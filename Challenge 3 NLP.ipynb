{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-geology",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%pip install transformers sklearn datasets ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "certain-overall",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(2)\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-waterproof",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Challenge 3: Sentiment analysis\n",
    "***\n",
    "We are interested in predicting the sentiment of written text.\n",
    "* For the challenge, we adopt the IMDb dataset of movie reviews:\n",
    "    * \"[...] *this film is very lovable in a way many comedies are not* '[...]\"\n",
    "\n",
    "The task is simple:\n",
    "* Predict whether a review has a positive or a negative sentiment\n",
    "    * Input: Paragraphs of text (string) and binary label (1: positive, 0: negative)\n",
    "    * Metric: Accuracy\n",
    "* Examples to get you started:\n",
    "    * Finetune transformer models, e.g. BERT\n",
    "    * Word2Vec + Deep Neural Network of your choice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-alabama",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hints\n",
    "***\n",
    "When training transformers:\n",
    "* The models are *huge*, so training will run very slowly\n",
    "    * Running several batches of the full training data will be a costly operation\n",
    "    * Google Colab needs you to do a captcha every 2h...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-invasion",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Loading the data\n",
    "***\n",
    "Using Huggingface `datasets` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "inappropriate-adapter",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (C:\\Users\\nikla\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\4ea52f2e58a08dbc12c2bd52d0d92b30b88c00230b4522801b3636782f625c5b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brilliant over-acting by Lesley Ann Warren. Best dramatic hobo lady I have ever seen, and love scenes in clothes warehouse are second to none. The corn on face is a classic, as good as anything in Blazing Saddles. The take on lawyers is also superb. After being accused of being a turncoat, selling out his boss, and being dishonest the lawyer of Pepto Bolt shrugs indifferently \"I'm a lawyer\" he says. Three funny words. Jeffrey Tambor, a favorite from the later Larry Sanders show, is fantastic here too as a mad millionaire who wants to crush the ghetto. His character is more malevolent than usual. The hospital scene, and the scene where the homeless invade a demolition site, are all-time classics. Look for the legs scene and the two big diggers fighting (one bleeds). This movie gets better each time I see it (which is quite often).\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "raw_datasets = load_dataset(\"imdb\")\n",
    "print(raw_datasets[\"train\"][\"text\"][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-inspector",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Dataset preprocessing\n",
    "***\n",
    "The function below translates the sentences to token IDs and splits into train and validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "functioning-terminal",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_and_split(datasets, tokenizer):\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "    tokenized_datasets = datasets.map(tokenize_function, batched=True)\n",
    "    train_dataset = tokenized_datasets[\"train\"]\n",
    "    eval_dataset = tokenized_datasets[\"test\"]\n",
    "    return train_dataset, eval_dataset\n",
    "\n",
    "def as_tf_dataset(dataset, tokenizer, batch_size=8):\n",
    "    tf_data = dataset.remove_columns([\"text\"]).with_format(\"tensorflow\")\n",
    "    train_features = {x: tf_data[x].to_tensor() for x in tokenizer.model_input_names}\n",
    "    tf_dataset = tf.data.Dataset.from_tensor_slices((train_features, tf_data[\"label\"]))\n",
    "    tf_dataset = tf_dataset.shuffle(len(tf_dataset)).batch(batch_size)\n",
    "    return tf_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-valuation",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Finetuning transformers\n",
    "***\n",
    "Huggingface's `transformers` library provides excellent functionality and many pretrained models\n",
    "* Let's load a smaller variant of BERT, called `DistilBert` and its tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "pursuant-encoding",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-adoption",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Run tokenization\n",
    "***\n",
    "Apply tokenizer and sample a small subset for showcasing the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-singapore",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_data, test_data = tokenize_and_split(raw_datasets, tokenizer)\n",
    "small_train_dataset = train_data.shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = test_data.shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-fiber",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Variant 1: Train using `keras`\n",
    "***\n",
    "We need to convert to a dataset format that `keras` understands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "beginning-falls",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ({input_ids: (None, 512), attention_mask: (None, 512)}, (None,)), types: ({input_ids: tf.int64, attention_mask: tf.int64}, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "tf_train_small = as_tf_dataset(small_train_dataset, tokenizer, batch_size=8)\n",
    "tf_eval_small = as_tf_dataset(small_eval_dataset, tokenizer, batch_size=8)\n",
    "print(tf_train_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-cleanup",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Loading the model\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "future-biodiversity",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_transform', 'vocab_layer_norm', 'vocab_projector', 'activation_13']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['dropout_39', 'pre_classifier', 'classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_distil_bert_for_sequence_classification_1\"\n",
      "__________________________________________________\n",
      "Layer (type)          Output Shape        Param # \n",
      "==================================================\n",
      "distilbert (TFDistilB multiple            66362880\n",
      "__________________________________________________\n",
      "pre_classifier (Dense multiple            590592  \n",
      "__________________________________________________\n",
      "classifier (Dense)    multiple            1538    \n",
      "__________________________________________________\n",
      "dropout_39 (Dropout)  multiple            0       \n",
      "==================================================\n",
      "Total params: 66,955,010\n",
      "Trainable params: 66,955,010\n",
      "Non-trainable params: 0\n",
      "__________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFDistilBertForSequenceClassification\n",
    "model = TFDistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
    "model.summary(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-season",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Time to train (`keras`)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "passing-advisory",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "125/125 [==============================] - 76s 607ms/step - loss: 0.6755 - sparse_categorical_accuracy: 0.5530 - val_loss: 0.6933 - val_sparse_categorical_accuracy: 0.5140\n",
      "Epoch 2/3\n",
      "125/125 [==============================] - 75s 603ms/step - loss: 0.5206 - sparse_categorical_accuracy: 0.7390 - val_loss: 0.4498 - val_sparse_categorical_accuracy: 0.7790\n",
      "Epoch 3/3\n",
      "125/125 [==============================] - 74s 594ms/step - loss: 0.3161 - sparse_categorical_accuracy: 0.8770 - val_loss: 0.5429 - val_sparse_categorical_accuracy: 0.7780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2954e23f9d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=5e-5),\n",
    "    loss= keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=tf.metrics.SparseCategoricalAccuracy(),\n",
    ")\n",
    "\n",
    "model.fit(tf_train_small, validation_data=tf_eval_small, epochs=3, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-zimbabwe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Evaluation code for `keras`\n",
    "***\n",
    "We run the final evaluation on the full test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "serious-settle",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "tf_eval_full = as_tf_dataset(test_data, tokenizer, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "nonprofit-attack",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 431s 276ms/step - loss: 0.5586 - sparse_categorical_accuracy: 0.7675\n",
      "Reached 0.768 accuracy and a loss of 0.5586\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(tf_eval_full)\n",
    "print(f\"Reached {acc:.3f} accuracy and a loss of {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-brunswick",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Variant 2: Train using PyTorch\n",
    "***\n",
    "The `transformers` framework comes with its own `Trainer` class which we can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-headquarters",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-faculty",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Specifying training arguments\n",
    "***\n",
    "The usual hyperparameters can be set using `TrainingArguments`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-bobby",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"results/\",\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=50,                # how often to log\n",
    "    evaluation_strategy=\"epoch\",     # when to run evaluation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-serve",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Adding accuracy metric\n",
    "***\n",
    "Evaluation workflow is a little different to what we are used from `keras`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-rough",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-renaissance",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Time to train (PyTorch)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-phase",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=small_train_dataset,   # training dataset\n",
    "    eval_dataset=small_eval_dataset,     # evaluation dataset\n",
    "    compute_metrics=compute_metrics,     # code to run accuracy metric\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-socket",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Evaluation code for PyTorch\n",
    "***\n",
    "We simply define a new `Trainer` that runs on the complete `eval_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-andrews",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=test_data,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "results = trainer.evaluate()\n",
    "loss, acc = results[\"eval_loss\"], results[\"eval_accuracy\"]\n",
    "print(f\"Reached {acc:.3f} accuracy and a loss of {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-cincinnati",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Applying Word2Vec\n",
    "***\n",
    "The previous state-of-the-art NLP models made heavy use of Word2Vec embeddings:\n",
    "1. Learn a word embedding on a large amount of text (unsupervised)\n",
    "    * It's also possible to train on task-specific text only\n",
    "2. Translate all words in an input sequence to their vectors\n",
    "3. Apply sequences of word vectors to a network model of your choice\n",
    "4. ???\n",
    "5. Profit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-forward",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-master",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Getting pre-trained vectors\n",
    "***\n",
    "`gensim` is a popular framework for training Word2Vec models. It also has a model zoo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "wound-poster",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import gensim.downloader\n",
    "print(list(gensim.downloader.info()['models'].keys()))\n",
    "# random pick:\n",
    "w2v = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suffering-sauce",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Here is the famous `king - man + woman = queen` example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "little-signature",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118193507194519),\n",
       " ('monarch', 0.6189674139022827),\n",
       " ('princess', 0.5902431011199951),\n",
       " ('crown_prince', 0.5499460697174072),\n",
       " ('prince', 0.5377321839332581),\n",
       " ('kings', 0.5236844420433044),\n",
       " ('Queen_Consort', 0.5235945582389832),\n",
       " ('queens', 0.5181134343147278),\n",
       " ('sultan', 0.5098593831062317),\n",
       " ('monarchy', 0.5087411999702454)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.most_similar(positive=[\"woman\", \"king\"], negative=[\"man\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-composite",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data preprocessing\n",
    "***\n",
    "For starters, we do the simplest possible tokenization: Splitting by `\" \"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cooked-fruit",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_w2v(w2v, dataset, sentence_function=None):\n",
    "    '''\n",
    "        sentence_function will be applied to each list of translated vectors.\n",
    "        This allows to save a lot of RAM when wishing to aggregate the paragraphs.\n",
    "    '''\n",
    "    x = []\n",
    "    y = np.array(dataset[\"label\"], \"int32\")\n",
    "    for text in tqdm(dataset[\"text\"]):\n",
    "        paragraph = [w2v[token] for token in text.split(\" \") if token in w2v]\n",
    "        if sentence_function is None:\n",
    "            paragraph = np.array(paragraph, \"float32\")\n",
    "        else: \n",
    "            paragraph = sentence_function(paragraph)\n",
    "        x.append(paragraph)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-pottery",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Getting rid of variable length data\n",
    "***\n",
    "For a first simple prototype, we simply sum up all word vectors of a review\n",
    "* Per review, we will get a single vector\n",
    "    * But is that a good approach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "confidential-channel",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 25000/25000 [00:15<00:00, 1581.34it/s]\n",
      "100%|██████████████████████████████████| 25000/25000 [00:15<00:00, 1633.21it/s]\n"
     ]
    }
   ],
   "source": [
    "sum_of_words = lambda vectors: np.sum(vectors, axis=0)\n",
    "x_train, y_train = tokenize_w2v(w2v, raw_datasets[\"train\"], sum_of_words)\n",
    "x_train = np.array(x_train)\n",
    "x_test, y_test = tokenize_w2v(w2v, raw_datasets[\"test\"],sum_of_words)\n",
    "x_test = np.array(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-classification",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Training with summed word vectors\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "lesbian-raising",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_19\"\n",
      "__________________________________________________\n",
      "Layer (type)          Output Shape        Param # \n",
      "==================================================\n",
      "input_12 (InputLayer) [(None, 300)]       0       \n",
      "__________________________________________________\n",
      "dense_38 (Dense)      (None, 128)         38528   \n",
      "__________________________________________________\n",
      "dropout_16 (Dropout)  (None, 128)         0       \n",
      "__________________________________________________\n",
      "dense_39 (Dense)      (None, 128)         16512   \n",
      "__________________________________________________\n",
      "dropout_17 (Dropout)  (None, 128)         0       \n",
      "__________________________________________________\n",
      "dense_40 (Dense)      (None, 128)         16512   \n",
      "__________________________________________________\n",
      "dense_41 (Dense)      (None, 2)           258     \n",
      "==================================================\n",
      "Total params: 71,810\n",
      "Trainable params: 71,810\n",
      "Non-trainable params: 0\n",
      "__________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Dropout,\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_layer = Input(w2v.vector_size)\n",
    "l = input_layer\n",
    "l = Dense(128, \"relu\")(l)\n",
    "l = Dropout(0.4)(l)\n",
    "l = Dense(2, \"softmax\")(l)\n",
    "model = Model(input_layer, l)\n",
    "model.summary(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "roman-gravity",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(x_train))\n",
    "np.random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-bridal",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(opt, \"sparse_categorical_crossentropy\", [\"accuracy\"])\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=1000,\n",
    "          verbose=2, validation_data=(x_test,y_test),)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-accused",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Evaluation code for W2V based models\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "established-breakdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6250/6250 [==============================] - 7s 1ms/step - loss: 0.5195 - accuracy: 0.7873\n",
      "Reached 0.787 accuracy and a loss of 0.5195\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test, batch_size=128)\n",
    "print(f\"Reached {acc:.3f} accuracy and a loss of {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-strand",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "rise": {
   "auto_select": "none",
   "enable_chalkboard": true,
   "overlay": "<div class='myheader'><img src='img/ai_camp.png' class='ifis_small'></div><div class='ifis_large'><img src='img/ifis_large.png'></div>",
   "scroll": true,
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
