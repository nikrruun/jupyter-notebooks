{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-geology",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%pip install transformers sklearn datasets ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "certain-overall",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.autograph.set_verbosity(2)\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-waterproof",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Challenge 3: Sentiment analysis\n",
    "***\n",
    "We are interested in predicting the sentiment of written text.\n",
    "* For the challenge, we adopt the IMDb dataset of movie reviews:\n",
    "    * \"[...] *this film is very lovable in a way many comedies are not* '[...]\"\n",
    "\n",
    "The task is simple:\n",
    "* Predict whether a review has a positive or a negative sentiment\n",
    "    * Input: Paragraphs of text (string) and binary label (1: positive, 0: negative)\n",
    "    * Metric: Accuracy\n",
    "* Examples to get you started:\n",
    "    * Finetune transformer models, e.g. BERT\n",
    "    * Word2Vec + Deep Neural Network of your choice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-alabama",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hints\n",
    "***\n",
    "When training transformers:\n",
    "* The models are *huge*, so training will run very slowly\n",
    "    * Running several batches of the full training data will be a costly operation\n",
    "    * Google Colab needs you to do a captcha every 2h...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-invasion",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Loading the data\n",
    "***\n",
    "Using Huggingface `datasets` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "inappropriate-adapter",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (C:\\Users\\nikla\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\4ea52f2e58a08dbc12c2bd52d0d92b30b88c00230b4522801b3636782f625c5b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brilliant over-acting by Lesley Ann Warren. Best dramatic hobo lady I have ever seen, and love scenes in clothes warehouse are second to none. The corn on face is a classic, as good as anything in Blazing Saddles. The take on lawyers is also superb. After being accused of being a turncoat, selling out his boss, and being dishonest the lawyer of Pepto Bolt shrugs indifferently \"I'm a lawyer\" he says. Three funny words. Jeffrey Tambor, a favorite from the later Larry Sanders show, is fantastic here too as a mad millionaire who wants to crush the ghetto. His character is more malevolent than usual. The hospital scene, and the scene where the homeless invade a demolition site, are all-time classics. Look for the legs scene and the two big diggers fighting (one bleeds). This movie gets better each time I see it (which is quite often).\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "raw_datasets = load_dataset(\"imdb\")\n",
    "print(raw_datasets[\"train\"][\"text\"][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-inspector",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Dataset preprocessing\n",
    "***\n",
    "The function below translates the sentences to token IDs and splits into train and validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "functioning-terminal",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_and_split(datasets, tokenizer):\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "    tokenized_datasets = datasets.map(tokenize_function, batched=True)\n",
    "    train_dataset = tokenized_datasets[\"train\"]\n",
    "    eval_dataset = tokenized_datasets[\"test\"]\n",
    "    return train_dataset, eval_dataset\n",
    "\n",
    "def as_tf_dataset(dataset, tokenizer, batch_size=8):\n",
    "    tf_data = dataset.remove_columns([\"text\"]).with_format(\"tensorflow\")\n",
    "    train_features = {x: tf_data[x].to_tensor() for x in tokenizer.model_input_names}\n",
    "    tf_dataset = tf.data.Dataset.from_tensor_slices((train_features, tf_data[\"label\"]))\n",
    "    tf_dataset = tf_dataset.shuffle(len(tf_dataset)).batch(batch_size)\n",
    "    return tf_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-valuation",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Finetuning transformers\n",
    "***\n",
    "Huggingface's `transformers` library provides excellent functionality and many pretrained models\n",
    "* Let's load a smaller variant of BERT, called `DistilBert` and its tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "pursuant-encoding",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-adoption",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Run tokenization\n",
    "***\n",
    "Apply tokenizer and sample a small subset for showcasing the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-singapore",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_data, test_data = tokenize_and_split(raw_datasets, tokenizer)\n",
    "small_train_dataset = train_data.shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = test_data.shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-fiber",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Variant 1: Train using `keras`\n",
    "***\n",
    "We need to convert to a dataset format that `keras` understands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "beginning-falls",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ({input_ids: (None, 512), attention_mask: (None, 512)}, (None,)), types: ({input_ids: tf.int64, attention_mask: tf.int64}, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "tf_train_small = as_tf_dataset(small_train_dataset, tokenizer, batch_size=8)\n",
    "tf_eval_small = as_tf_dataset(small_eval_dataset, tokenizer, batch_size=8)\n",
    "print(tf_train_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-cleanup",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Loading the model\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "future-biodiversity",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['vocab_transform', 'vocab_layer_norm', 'vocab_projector', 'activation_13']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['dropout_39', 'pre_classifier', 'classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_distil_bert_for_sequence_classification_1\"\n",
      "__________________________________________________\n",
      "Layer (type)          Output Shape        Param # \n",
      "==================================================\n",
      "distilbert (TFDistilB multiple            66362880\n",
      "__________________________________________________\n",
      "pre_classifier (Dense multiple            590592  \n",
      "__________________________________________________\n",
      "classifier (Dense)    multiple            1538    \n",
      "__________________________________________________\n",
      "dropout_39 (Dropout)  multiple            0       \n",
      "==================================================\n",
      "Total params: 66,955,010\n",
      "Trainable params: 66,955,010\n",
      "Non-trainable params: 0\n",
      "__________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFDistilBertForSequenceClassification\n",
    "model = TFDistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
    "model.summary(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-season",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Time to train (`keras`)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "passing-advisory",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "125/125 [==============================] - 76s 607ms/step - loss: 0.6755 - sparse_categorical_accuracy: 0.5530 - val_loss: 0.6933 - val_sparse_categorical_accuracy: 0.5140\n",
      "Epoch 2/3\n",
      "125/125 [==============================] - 75s 603ms/step - loss: 0.5206 - sparse_categorical_accuracy: 0.7390 - val_loss: 0.4498 - val_sparse_categorical_accuracy: 0.7790\n",
      "Epoch 3/3\n",
      "125/125 [==============================] - 74s 594ms/step - loss: 0.3161 - sparse_categorical_accuracy: 0.8770 - val_loss: 0.5429 - val_sparse_categorical_accuracy: 0.7780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2954e23f9d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=5e-5),\n",
    "    loss= keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=tf.metrics.SparseCategoricalAccuracy(),\n",
    ")\n",
    "\n",
    "model.fit(tf_train_small, validation_data=tf_eval_small, epochs=3, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-zimbabwe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Evaluation code for `keras`\n",
    "***\n",
    "We run the final evaluation on the full test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "serious-settle",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "tf_eval_full = as_tf_dataset(test_data, tokenizer, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "nonprofit-attack",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 431s 276ms/step - loss: 0.5586 - sparse_categorical_accuracy: 0.7675\n",
      "Reached 0.768 accuracy and a loss of 0.5586\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(tf_eval_full)\n",
    "print(f\"Reached {acc:.3f} accuracy and a loss of {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-brunswick",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Variant 2: Train using PyTorch\n",
    "***\n",
    "The `transformers` framework comes with its own `Trainer` class which we can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-headquarters",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prospective-faculty",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Specifying training arguments\n",
    "***\n",
    "The usual hyperparameters can be set using `TrainingArguments`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-bobby",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"results/\",\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=16,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=50,                # how often to log\n",
    "    evaluation_strategy=\"epoch\",     # when to run evaluation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-serve",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Adding accuracy metric\n",
    "***\n",
    "Evaluation workflow is a little different to what we are used from `keras`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-rough",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-renaissance",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Time to train (PyTorch)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-phase",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=small_train_dataset,   # training dataset\n",
    "    eval_dataset=small_eval_dataset,     # evaluation dataset\n",
    "    compute_metrics=compute_metrics,     # code to run accuracy metric\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-socket",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Evaluation code for PyTorch\n",
    "***\n",
    "We simply define a new `Trainer` that runs on the complete `eval_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-andrews",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=test_data,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "results = trainer.evaluate()\n",
    "loss, acc = results[\"eval_loss\"], results[\"eval_accuracy\"]\n",
    "print(f\"Reached {acc:.3f} accuracy and a loss of {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-cincinnati",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Applying Word2Vec\n",
    "***\n",
    "The previous state-of-the-art NLP models made heavy use of Word2Vec embeddings:\n",
    "1. Learn a word embedding on a large amount of text (unsupervised)\n",
    "    * It's also possible to train on task-specific text only\n",
    "2. Translate all words in an input sequence to their vectors\n",
    "3. Apply sequences of word vectors to a network model of your choice\n",
    "4. ???\n",
    "5. Profit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-forward",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-master",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Getting pre-trained vectors\n",
    "***\n",
    "`gensim` is a popular framework for training Word2Vec models. It also has a model zoo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "wound-poster",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nikla\\workspace\\jupyter-notebooks\\env\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import gensim.downloader\n",
    "print(list(gensim.downloader.info()['models'].keys()))\n",
    "# random pick:\n",
    "w2v = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suffering-sauce",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Here is the famous `king - man + woman = queen` example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "little-signature",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118193507194519),\n",
       " ('monarch', 0.6189674139022827),\n",
       " ('princess', 0.5902431011199951),\n",
       " ('crown_prince', 0.5499460697174072),\n",
       " ('prince', 0.5377321839332581),\n",
       " ('kings', 0.5236844420433044),\n",
       " ('Queen_Consort', 0.5235945582389832),\n",
       " ('queens', 0.5181134343147278),\n",
       " ('sultan', 0.5098593831062317),\n",
       " ('monarchy', 0.5087411999702454)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.most_similar(positive=[\"woman\", \"king\"], negative=[\"man\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-composite",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data preprocessing\n",
    "***\n",
    "For starters, we do the simplest possible tokenization: Splitting by `\" \"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cooked-fruit",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_w2v(w2v, dataset, sentence_function=None):\n",
    "    '''\n",
    "        sentence_function will be applied to each list of translated vectors.\n",
    "        This allows to save a lot of RAM when wishing to aggregate the paragraphs.\n",
    "    '''\n",
    "    x = []\n",
    "    y = np.array(dataset[\"label\"], \"int32\")\n",
    "    for text in tqdm(dataset[\"text\"]):\n",
    "        paragraph = [w2v[token] for token in text.split(\" \") if token in w2v]\n",
    "        if sentence_function is None:\n",
    "            paragraph = np.array(paragraph, \"float32\")\n",
    "        else: \n",
    "            paragraph = sentence_function(paragraph)\n",
    "        x.append(paragraph)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-pottery",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Getting rid of variable length data\n",
    "***\n",
    "For a first simple prototype, we simply sum up all word vectors of a review\n",
    "* Per review, we will get a single vector\n",
    "    * But is that a good approach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "confidential-channel",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 25000/25000 [00:16<00:00, 1501.29it/s]\n",
      "100%|██████████████████████████████████| 25000/25000 [00:17<00:00, 1441.55it/s]\n"
     ]
    }
   ],
   "source": [
    "sum_of_words = lambda vectors: np.sum(vectors, axis=0)\n",
    "x_train, y_train = tokenize_w2v(w2v, raw_datasets[\"train\"], sum_of_words)\n",
    "x_train = np.array(x_train)\n",
    "x_test, y_test = tokenize_w2v(w2v, raw_datasets[\"test\"],sum_of_words)\n",
    "x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-classification",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Training with summed word vectors\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "lesbian-raising",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________\n",
      "Layer (type)          Output Shape        Param # \n",
      "==================================================\n",
      "input_1 (InputLayer)  [(None, 300)]       0       \n",
      "__________________________________________________\n",
      "dense (Dense)         (None, 128)         38528   \n",
      "__________________________________________________\n",
      "dropout (Dropout)     (None, 128)         0       \n",
      "__________________________________________________\n",
      "dense_1 (Dense)       (None, 2)           258     \n",
      "==================================================\n",
      "Total params: 38,786\n",
      "Trainable params: 38,786\n",
      "Non-trainable params: 0\n",
      "__________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Dropout,\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_layer = Input(w2v.vector_size)\n",
    "l = input_layer\n",
    "l = Dense(128, \"relu\")(l)\n",
    "l = Dropout(0.4)(l)\n",
    "l = Dense(2, \"softmax\")(l)\n",
    "model = Model(input_layer, l)\n",
    "model.summary(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "compact-bridal",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "157/157 - 1s - loss: 0.9240 - accuracy: 0.7169 - val_loss: 0.6332 - val_accuracy: 0.6886\n",
      "Epoch 2/1000\n",
      "157/157 - 0s - loss: 0.4709 - accuracy: 0.7873 - val_loss: 0.5447 - val_accuracy: 0.7446\n",
      "Epoch 3/1000\n",
      "157/157 - 0s - loss: 0.4405 - accuracy: 0.8031 - val_loss: 0.6022 - val_accuracy: 0.7082\n",
      "Epoch 4/1000\n",
      "157/157 - 0s - loss: 0.4248 - accuracy: 0.8144 - val_loss: 0.3471 - val_accuracy: 0.8662\n",
      "Epoch 5/1000\n",
      "157/157 - 0s - loss: 0.4100 - accuracy: 0.8205 - val_loss: 0.5675 - val_accuracy: 0.7412\n",
      "Epoch 6/1000\n",
      "157/157 - 0s - loss: 0.4054 - accuracy: 0.8219 - val_loss: 0.5051 - val_accuracy: 0.7778\n",
      "Epoch 7/1000\n",
      "157/157 - 0s - loss: 0.3993 - accuracy: 0.8264 - val_loss: 0.4766 - val_accuracy: 0.7964\n",
      "Epoch 8/1000\n",
      "157/157 - 0s - loss: 0.3966 - accuracy: 0.8281 - val_loss: 0.4544 - val_accuracy: 0.8004\n",
      "Epoch 9/1000\n",
      "157/157 - 0s - loss: 0.3972 - accuracy: 0.8269 - val_loss: 0.6355 - val_accuracy: 0.7110\n",
      "Epoch 10/1000\n",
      "157/157 - 0s - loss: 0.3932 - accuracy: 0.8291 - val_loss: 0.5048 - val_accuracy: 0.7644\n",
      "Epoch 11/1000\n",
      "157/157 - 0s - loss: 0.3886 - accuracy: 0.8284 - val_loss: 0.7032 - val_accuracy: 0.6360\n",
      "Epoch 12/1000\n",
      "157/157 - 0s - loss: 0.3861 - accuracy: 0.8329 - val_loss: 0.4967 - val_accuracy: 0.7784\n",
      "Epoch 13/1000\n",
      "157/157 - 0s - loss: 0.3806 - accuracy: 0.8380 - val_loss: 0.6347 - val_accuracy: 0.6914\n",
      "Epoch 14/1000\n",
      "157/157 - 0s - loss: 0.3755 - accuracy: 0.8370 - val_loss: 0.4565 - val_accuracy: 0.7816\n",
      "Epoch 15/1000\n",
      "157/157 - 0s - loss: 0.3731 - accuracy: 0.8379 - val_loss: 0.4782 - val_accuracy: 0.7850\n",
      "Epoch 16/1000\n",
      "157/157 - 0s - loss: 0.3790 - accuracy: 0.8352 - val_loss: 0.3624 - val_accuracy: 0.8490\n",
      "Epoch 17/1000\n",
      "157/157 - 0s - loss: 0.3727 - accuracy: 0.8370 - val_loss: 0.5328 - val_accuracy: 0.7572\n",
      "Epoch 18/1000\n",
      "157/157 - 0s - loss: 0.3797 - accuracy: 0.8324 - val_loss: 0.4169 - val_accuracy: 0.8250\n",
      "Epoch 19/1000\n",
      "157/157 - 0s - loss: 0.3708 - accuracy: 0.8376 - val_loss: 0.5372 - val_accuracy: 0.7350\n",
      "Epoch 20/1000\n",
      "157/157 - 0s - loss: 0.3684 - accuracy: 0.8392 - val_loss: 0.5553 - val_accuracy: 0.7562\n",
      "Epoch 21/1000\n",
      "157/157 - 0s - loss: 0.3649 - accuracy: 0.8414 - val_loss: 0.5139 - val_accuracy: 0.7608\n",
      "Epoch 22/1000\n",
      "157/157 - 0s - loss: 0.3613 - accuracy: 0.8417 - val_loss: 0.6279 - val_accuracy: 0.6816\n",
      "Epoch 23/1000\n",
      "157/157 - 0s - loss: 0.3694 - accuracy: 0.8372 - val_loss: 0.4767 - val_accuracy: 0.7814\n",
      "Epoch 24/1000\n",
      "157/157 - 0s - loss: 0.3674 - accuracy: 0.8414 - val_loss: 0.4791 - val_accuracy: 0.7778\n",
      "Epoch 25/1000\n",
      "157/157 - 0s - loss: 0.3705 - accuracy: 0.8359 - val_loss: 0.6069 - val_accuracy: 0.6852\n",
      "Epoch 26/1000\n",
      "157/157 - 0s - loss: 0.3655 - accuracy: 0.8402 - val_loss: 0.5900 - val_accuracy: 0.7168\n",
      "Epoch 27/1000\n",
      "157/157 - 0s - loss: 0.3668 - accuracy: 0.8370 - val_loss: 0.4722 - val_accuracy: 0.7810\n",
      "Epoch 28/1000\n",
      "157/157 - 0s - loss: 0.3657 - accuracy: 0.8398 - val_loss: 0.4098 - val_accuracy: 0.8262\n",
      "Epoch 29/1000\n",
      "157/157 - 0s - loss: 0.3699 - accuracy: 0.8419 - val_loss: 0.4831 - val_accuracy: 0.7698\n",
      "Epoch 30/1000\n",
      "157/157 - 0s - loss: 0.3674 - accuracy: 0.8395 - val_loss: 0.5511 - val_accuracy: 0.7394\n",
      "Epoch 31/1000\n",
      "157/157 - 0s - loss: 0.3662 - accuracy: 0.8411 - val_loss: 0.5933 - val_accuracy: 0.7094\n",
      "Epoch 32/1000\n",
      "157/157 - 0s - loss: 0.3599 - accuracy: 0.8439 - val_loss: 0.3963 - val_accuracy: 0.8084\n",
      "Epoch 33/1000\n",
      "157/157 - 0s - loss: 0.3676 - accuracy: 0.8408 - val_loss: 0.6217 - val_accuracy: 0.6862\n",
      "Epoch 34/1000\n",
      "157/157 - 0s - loss: 0.3673 - accuracy: 0.8411 - val_loss: 0.6140 - val_accuracy: 0.7222\n",
      "Epoch 35/1000\n",
      "157/157 - 0s - loss: 0.3700 - accuracy: 0.8388 - val_loss: 0.4835 - val_accuracy: 0.7480\n",
      "Epoch 36/1000\n",
      "157/157 - 0s - loss: 0.3628 - accuracy: 0.8436 - val_loss: 0.5747 - val_accuracy: 0.7000\n",
      "Epoch 37/1000\n",
      "157/157 - 0s - loss: 0.3639 - accuracy: 0.8415 - val_loss: 0.5469 - val_accuracy: 0.7324\n",
      "Epoch 38/1000\n",
      "157/157 - 0s - loss: 0.3599 - accuracy: 0.8426 - val_loss: 0.3757 - val_accuracy: 0.8376\n",
      "Epoch 39/1000\n",
      "157/157 - 0s - loss: 0.3620 - accuracy: 0.8432 - val_loss: 0.5770 - val_accuracy: 0.7114\n",
      "Epoch 40/1000\n",
      "157/157 - 0s - loss: 0.3609 - accuracy: 0.8481 - val_loss: 0.4051 - val_accuracy: 0.8008\n",
      "Epoch 41/1000\n",
      "157/157 - 0s - loss: 0.3527 - accuracy: 0.8475 - val_loss: 0.5509 - val_accuracy: 0.7364\n",
      "Epoch 42/1000\n",
      "157/157 - 0s - loss: 0.3563 - accuracy: 0.8492 - val_loss: 0.5157 - val_accuracy: 0.7710\n",
      "Epoch 43/1000\n",
      "157/157 - 0s - loss: 0.3542 - accuracy: 0.8481 - val_loss: 0.5092 - val_accuracy: 0.7512\n",
      "Epoch 44/1000\n",
      "157/157 - 0s - loss: 0.3506 - accuracy: 0.8486 - val_loss: 0.4876 - val_accuracy: 0.7654\n",
      "Epoch 45/1000\n",
      "157/157 - 0s - loss: 0.3530 - accuracy: 0.8468 - val_loss: 0.5286 - val_accuracy: 0.7490\n",
      "Epoch 46/1000\n",
      "157/157 - 0s - loss: 0.3482 - accuracy: 0.8477 - val_loss: 0.5269 - val_accuracy: 0.7436\n",
      "Epoch 47/1000\n",
      "157/157 - 0s - loss: 0.3475 - accuracy: 0.8488 - val_loss: 0.5024 - val_accuracy: 0.7606\n",
      "Epoch 48/1000\n",
      "157/157 - 0s - loss: 0.3462 - accuracy: 0.8491 - val_loss: 0.4105 - val_accuracy: 0.8220\n",
      "Epoch 49/1000\n",
      "157/157 - 0s - loss: 0.3522 - accuracy: 0.8476 - val_loss: 0.5525 - val_accuracy: 0.7470\n",
      "Epoch 50/1000\n",
      "157/157 - 0s - loss: 0.3481 - accuracy: 0.8489 - val_loss: 0.5363 - val_accuracy: 0.7382\n",
      "Epoch 51/1000\n",
      "157/157 - 0s - loss: 0.3481 - accuracy: 0.8479 - val_loss: 0.5937 - val_accuracy: 0.7338\n",
      "Epoch 52/1000\n",
      "157/157 - 0s - loss: 0.3485 - accuracy: 0.8510 - val_loss: 0.5121 - val_accuracy: 0.7626\n",
      "Epoch 53/1000\n",
      "157/157 - 0s - loss: 0.3498 - accuracy: 0.8506 - val_loss: 0.5222 - val_accuracy: 0.7498\n",
      "Epoch 54/1000\n",
      "157/157 - 0s - loss: 0.3429 - accuracy: 0.8550 - val_loss: 0.4710 - val_accuracy: 0.7684\n",
      "Epoch 55/1000\n",
      "157/157 - 0s - loss: 0.3449 - accuracy: 0.8498 - val_loss: 0.4622 - val_accuracy: 0.7726\n",
      "Epoch 56/1000\n",
      "157/157 - 0s - loss: 0.3425 - accuracy: 0.8508 - val_loss: 0.4395 - val_accuracy: 0.8090\n",
      "Epoch 57/1000\n",
      "157/157 - 0s - loss: 0.3404 - accuracy: 0.8533 - val_loss: 0.4965 - val_accuracy: 0.7760\n",
      "Epoch 58/1000\n",
      "157/157 - 0s - loss: 0.3426 - accuracy: 0.8500 - val_loss: 0.5010 - val_accuracy: 0.7714\n",
      "Epoch 59/1000\n",
      "157/157 - 0s - loss: 0.3447 - accuracy: 0.8499 - val_loss: 0.4508 - val_accuracy: 0.7800\n",
      "Epoch 60/1000\n",
      "157/157 - 0s - loss: 0.3478 - accuracy: 0.8502 - val_loss: 0.4552 - val_accuracy: 0.7964\n",
      "Epoch 61/1000\n",
      "157/157 - 0s - loss: 0.3473 - accuracy: 0.8513 - val_loss: 0.5643 - val_accuracy: 0.7508\n",
      "Epoch 62/1000\n",
      "157/157 - 0s - loss: 0.3479 - accuracy: 0.8484 - val_loss: 0.6588 - val_accuracy: 0.6872\n",
      "Epoch 63/1000\n",
      "157/157 - 0s - loss: 0.3510 - accuracy: 0.8461 - val_loss: 0.5082 - val_accuracy: 0.7512\n",
      "Epoch 64/1000\n",
      "157/157 - 0s - loss: 0.3432 - accuracy: 0.8515 - val_loss: 0.5671 - val_accuracy: 0.7076\n",
      "Epoch 65/1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-604ed087edb2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sparse_categorical_crossentropy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m model.fit(x_train, y_train, batch_size=128, epochs=1000,\n\u001b[0m\u001b[0;32m      4\u001b[0m           verbose=2, validation_split=0.2)\n",
      "\u001b[1;32mc:\\users\\nikla\\workspace\\jupyter-notebooks\\env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikla\\workspace\\jupyter-notebooks\\env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1121\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1123\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1124\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikla\\workspace\\jupyter-notebooks\\env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikla\\workspace\\jupyter-notebooks\\env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[0;32m   1382\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1383\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikla\\workspace\\jupyter-notebooks\\env\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_test_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    460\u001b[0m     \"\"\"\n\u001b[0;32m    461\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_test_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikla\\workspace\\jupyter-notebooks\\env\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    290\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Unrecognized hook: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikla\\workspace\\jupyter-notebooks\\env\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikla\\workspace\\jupyter-notebooks\\env\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    343\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Only convert once.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m           \u001b[0mnumpy_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikla\\workspace\\jupyter-notebooks\\env\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 537\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikla\\workspace\\jupyter-notebooks\\env\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikla\\workspace\\jupyter-notebooks\\env\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikla\\workspace\\jupyter-notebooks\\env\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    531\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 533\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikla\\workspace\\jupyter-notebooks\\env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m     \"\"\"\n\u001b[0;32m   1062\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1063\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1064\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1065\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikla\\workspace\\jupyter-notebooks\\env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1027\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1030\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(opt, \"sparse_categorical_crossentropy\", [\"accuracy\"])\n",
    "model.fit(x_train, y_train, batch_size=128, epochs=1000,\n",
    "          verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-accused",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Evaluation code for W2V based models\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "established-breakdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 1ms/step - loss: 0.4770 - accuracy: 0.7652\n",
      "Reached 0.765 accuracy and a loss of 0.4770\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test, batch_size=128)\n",
    "print(f\"Reached {acc:.3f} accuracy and a loss of {loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-strand",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "rise": {
   "auto_select": "none",
   "enable_chalkboard": true,
   "overlay": "<div class='myheader'><img src='img/ai_camp.png' class='ifis_small'></div><div class='ifis_large'><img src='img/ifis_large.png'></div>",
   "scroll": true,
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
