{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cleared-friday",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# TODO\n",
    "* Leitfaden zur Reproduzierung der Slides und Code f√ºr\n",
    "    * Just Code\n",
    "        Remote: CPU/GPU: Colab\n",
    "        Remote: CPU only: Blender\n",
    "        Local: Clone Repo and follow instructions\n",
    "    * Code with slides:\n",
    "        Remote: CPU only: Blender\n",
    "        Local CPU/GPU: Clone repo and follow instructions\n",
    "* Better CSS for IFIS style slides\n",
    "    * Have H1 headings on top of screen\n",
    "    * Have horizontal lines above and below H1 headings\n",
    "    * Have Content starting at fixed height\n",
    "    * Add a footer with author name and Institute\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-macro",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# AI Camp 2020 Kickoff\n",
    "## Welcome!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-assembly",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Agenda\n",
    "* Ziele\n",
    "* Organisatorisches\n",
    "    * Coding usw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thrown-slide",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Ziele\n",
    "blabla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-albert",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Organisatorisches\n",
    " - Lectures & Examples in Python\n",
    "     - Frameworks: Tensorflow, Pytorch, sklearn, etc.\n",
    " - Slides & Code in <a href=\"https://jupyter.org/\">Jupyter Notebooks</a>\n",
    " - Everything is located in Niklas' <a href=\"https://github.com/nikrruun/jupyter-notebooks/tree/aicamp2020\">GitHub Repo</a>\n",
    "     - Branch \"aicamp2020\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-hammer",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Why Jupyter Notebooks?\n",
    "We want to present math and code for sophisticated AI models\n",
    "> We have PowerPoint for this!\n",
    "\n",
    "But wouldn't it be nice, if we also could\n",
    "- Actually run the code during presentation\n",
    "- Interact with it and observe changes\n",
    "- Easily share it and ship to remote hardware\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-sunrise",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# You're in a simulation\n",
    "This presentation is a Jupyter Notebook too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abandoned-oasis",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2^0 = 1\n",
      "2^1 = 2\n",
      "2^2 = 4\n",
      "2^3 = 8\n",
      "2^4 = 16\n",
      "2^5 = 32\n",
      "2^6 = 64\n",
      "2^7 = 128\n",
      "2^8 = 256\n",
      "2^9 = 512\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for i in range(10):\n",
    "    print(f\"2^{i} =\", 2**i)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defensive-citizen",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And it's also interactive!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-possibility",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Features \n",
    "* Inline Latex support: $e^yx_k\\sum_{i=1}{2^{-i}}$\n",
    "* Text narratives via markdown (essentially a readme.md)\n",
    "* Usually, a notebook is a list of sequential code or text cells\n",
    "    - But, with some effort it automatically translates into a slideshow\n",
    "* Run a copy on <a href=\"https://colab.research.google.com\">Google Colab</a> in < 1 minute\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-detective",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Google Colab walkthrough\n",
    "1. Open the link <a href=\"https://colab.research.google.com\">Google Colab</a>\n",
    "2. Sign up & in, and open a new notebook\n",
    "3. Go to tab \"GitHub\" and search for user \"nikrruun\". Choose as shown below:\n",
    "<img src=\"img/slides/colab_github_menu.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-yemen",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Google Colab (2)\n",
    "4. Click on \"<i>kickoff_presentation.ipynb</i>\"\n",
    "    - Generally, Google Colab filters out all available notebooks from a given repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lasting-salmon",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,5))\n",
    "a = plt.plot(np.random.rand(10), \"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "inner-calibration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Input, Dropout    \n",
    ")\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import Huber\n",
    "from tensorflow import keras\n",
    "\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "complex-player",
   "metadata": {},
   "outputs": [],
   "source": [
    "def episode(env, model, render=False, max_steps=None):\n",
    "    states = []\n",
    "    action_probs = []\n",
    "    est_rewards = []\n",
    "    rewards = []\n",
    "\n",
    "    state = env.reset()\n",
    "    i = 0\n",
    "    while i < (j := max_steps if max_steps is not None else np.inf):\n",
    "        if render: \n",
    "            env.render()\n",
    "        state = tf.convert_to_tensor(state)\n",
    "        state = tf.expand_dims(state, 0)\n",
    "        states.append(state)\n",
    "\n",
    "        a_p, e_w = model(state)\n",
    "        action = np.random.choice(env.action_space.n, p=np.squeeze(a_p))\n",
    "        state, reward, done, info = env.step(action)\n",
    "\n",
    "        action_probs.append(a_p[0, action])\n",
    "        est_rewards.append(e_w[0,0])\n",
    "        rewards.append(reward)\n",
    "\n",
    "        i += 1\n",
    "        if done:\n",
    "            break\n",
    "    env.close()\n",
    "    return states, rewards, action_probs, est_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "false-yesterday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          640         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           8256        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "actor (Dense)                   (None, 2)            130         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "critic (Dense)                  (None, 1)            65          dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 9,091\n",
      "Trainable params: 9,091\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "gamma = 0.9\n",
    "train_max_steps = 200\n",
    "validation_every = 5\n",
    "validation_episodes = 5\n",
    "validation_max_steps = 200\n",
    "env = gym.make('CartPole-v0').unwrapped\n",
    "#env = gym.make('MountainCar-v0').unwrapped\n",
    "\n",
    "critic_loss_func = keras.losses.Huber()\n",
    "\n",
    "input_layer = Input(env.observation_space.shape)\n",
    "l = Dense(128, \"relu\")(input_layer)\n",
    "l = Dense(64, \"relu\")(l)\n",
    "actor = Dense(env.action_space.n, \"softmax\", name=\"actor\")(l)\n",
    "critic = Dense(1, name=\"critic\")(l)\n",
    "model = Model(input_layer, [actor, critic])\n",
    "\n",
    "model.summary()\n",
    "opt = keras.optimizers.Adam(lr=0.01)\n",
    "reward_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "opened-founder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1000 0 10.0 12.0 30.0 20.8\n",
      "Epoch 5/1000 5 13.0 10.0 39.0 19.6\n",
      "Epoch 10/1000 10 17.6 9.0 31.0 19.4\n",
      "Epoch 15/1000 15 14.0 10.0 20.0 15.4\n",
      "Epoch 20/1000 20 12.2 10.0 15.0 12.4\n",
      "Epoch 25/1000 25 14.4 9.0 13.0 11.0\n",
      "Epoch 30/1000 30 11.4 11.0 16.0 13.8\n",
      "Epoch 35/1000 35 15.8 10.0 13.0 12.0\n",
      "Epoch 40/1000 40 14.6 10.0 16.0 13.0\n",
      "Epoch 45/1000 45 15.8 17.0 31.0 23.2\n",
      "Epoch 50/1000 50 31.2 12.0 23.0 15.6\n",
      "Epoch 55/1000 55 19.4 12.0 58.0 30.6\n",
      "Epoch 60/1000 60 18.6 14.0 26.0 20.2\n",
      "Epoch 65/1000 65 41.6 13.0 35.0 20.2\n",
      "Epoch 70/1000 70 40.0 12.0 18.0 14.4\n",
      "Epoch 75/1000 75 15.6 16.0 39.0 22.6\n",
      "Epoch 80/1000 80 19.0 8.0 16.0 11.8\n",
      "Epoch 85/1000 85 13.8 13.0 33.0 21.0\n",
      "Epoch 90/1000 90 21.6 15.0 35.0 22.6\n",
      "Epoch 95/1000 95 34.8 13.0 71.0 34.6\n",
      "Epoch 100/1000 100 55.2 13.0 43.0 23.0\n",
      "Epoch 105/1000 105 26.2 25.0 52.0 35.8\n",
      "Epoch 110/1000 110 21.6 14.0 54.0 30.6\n",
      "Epoch 115/1000 115 40.6 15.0 70.0 40.4\n",
      "Epoch 120/1000 120 28.0 23.0 64.0 45.0\n",
      "Epoch 125/1000 125 26.0 12.0 20.0 15.2\n",
      "Epoch 130/1000 130 12.4 9.0 28.0 17.8\n",
      "Epoch 135/1000 135 12.8 8.0 19.0 12.8\n",
      "Epoch 140/1000 140 15.4 11.0 18.0 14.0\n",
      "Epoch 145/1000 145 16.2 10.0 18.0 14.2\n",
      "Epoch 150/1000 150 10.6 12.0 21.0 15.2\n",
      "Epoch 155/1000 155 12.4 11.0 34.0 16.2\n",
      "Epoch 160/1000 160 12.4 11.0 19.0 15.0\n",
      "Epoch 165/1000 165 22.4 16.0 181.0 60.2\n",
      "Epoch 170/1000 170 42.2 13.0 126.0 52.4\n",
      "Epoch 175/1000 175 129.8 142.0 181.0 163.6\n",
      "Epoch 180/1000 180 90.6 139.0 172.0 150.2\n",
      "Epoch 185/1000 185 188.2 200.0 200.0 200.0\n",
      "Epoch 190/1000 190 181.2 200.0 200.0 200.0\n",
      "Epoch 195/1000 195 162.4 16.0 200.0 126.8\n",
      "Epoch 200/1000 200 91.4 10.0 200.0 87.4\n",
      "Epoch 205/1000 205 50.0 9.0 13.0 11.4\n",
      "Epoch 210/1000 210 11.4 13.0 132.0 56.2\n",
      "Epoch 215/1000 215 81.6 15.0 197.0 154.8\n",
      "Epoch 220/1000 220 161.6 200.0 200.0 200.0\n",
      "Epoch 225/1000 225 200.0 71.0 200.0 174.2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-14a0a7a24b1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactor_loss\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcritic_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikla\\workspace\\jupyter-notebooks\\env\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1078\u001b[0m                           for x in nest.flatten(output_gradients)]\n\u001b[0;32m   1079\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1080\u001b[1;33m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[0;32m   1081\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikla\\workspace\\jupyter-notebooks\\env\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[0;32m     72\u001b[0m       \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikla\\workspace\\jupyter-notebooks\\env\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    160\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikla\\workspace\\jupyter-notebooks\\env\\lib\\site-packages\\tensorflow\\python\\ops\\array_grad.py\u001b[0m in \u001b[0;36m_StridedSliceGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    283\u001b[0m   \u001b[0mstrides\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstrides_static\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mstrides_static\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m   return array_ops.strided_slice_grad(\n\u001b[0m\u001b[0;32m    286\u001b[0m       \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m       \u001b[0mbegin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikla\\workspace\\jupyter-notebooks\\env\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mstrided_slice_grad\u001b[1;34m(shape, begin, end, strides, dy, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[0;32m  10632\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10633\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10634\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m  10635\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"StridedSliceGrad\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbegin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10636\u001b[0m         \u001b[1;34m\"begin_mask\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbegin_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"end_mask\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ellipsis_mask\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        states, rewards, action_probs, est_rewards = episode(env, model, False, train_max_steps)\n",
    "        reward_history.append(sum(rewards))\n",
    "\n",
    "        returns = []\n",
    "        discounted_sum = 0\n",
    "        for r in rewards[::-1]:\n",
    "            discounted_sum = r + gamma * discounted_sum\n",
    "            returns.insert(0, discounted_sum)\n",
    "        returns = np.array(returns)\n",
    "        returns = (returns - returns.mean()) / returns.std()\n",
    "\n",
    "        critic_labels = tf.convert_to_tensor(returns, \"float32\")\n",
    "\n",
    "        # critic_loss = critic_loss_func(est_rewards, critic_labels)\n",
    "        cl = []\n",
    "        for f,g in zip(est_rewards, critic_labels):\n",
    "            cl.append(critic_loss_func(tf.expand_dims(f,0), tf.expand_dims(g,0)))\n",
    "        critic_loss = sum(cl)\n",
    "\n",
    "        al = -tf.math.log(action_probs) * (critic_labels - est_rewards)\n",
    "        actor_loss = sum(al)\n",
    "        loss = actor_loss + critic_loss\n",
    "\n",
    "        gradients = tape.gradient(loss, model.trainable_weights)\n",
    "        opt.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "    if epoch % validation_every == 0:\n",
    "        val_rewards = []\n",
    "        for val_e in range(validation_episodes):\n",
    "            states, rewards, action_probs, est_rewards = episode(env, model, False, validation_max_steps)\n",
    "            val_rewards.append(sum(rewards))\n",
    "        val_rewards = np.array(val_rewards)\n",
    "        print(f\"Epoch {epoch}/{epochs}\",np.mean(reward_history),  val_rewards.min(), val_rewards.max(), val_rewards.mean())\n",
    "        reward_history.clear()\n",
    "        #episode(env, model, True, validation_max_steps)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-management",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "rise": {
   "auto_select": "none",
   "enable_chalkboard": true,
   "overlay": "<div class='myheader'><img src='img/ifis_small.png' class='ifis_small'></div><div class='ifis_large'><img src='img/ifis_large.png' class='ifis_large'></div>",
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
