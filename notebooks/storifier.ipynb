{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c9a3812",
   "metadata": {},
   "source": [
    "# Storifier-Transformer\n",
    "***\n",
    "For the `Moral Reasoning - Moral = Reasoning` experiment we need to exemplify the norm as an action:\n",
    "* Given a norm: \"It is bad to hurt someone\"\n",
    "* And an actor: \"Kevin\"\n",
    "* Using the `Learn2Split` model we get (`bad`,`hurting someone`)\n",
    "* We want: \"Kevin hurts someone\"\n",
    "\n",
    "In this notebook, I want to test whether `seq2seq` transformers can generate such sentences given the input pair of `norm_action` and `name`.\n",
    "\n",
    "Experiment outline:\n",
    "1. Take the handcrafted `norm_stories` from the prototype\n",
    "    1. We take the labeled subset as training data and the unlabeled are test\n",
    "2. Train a `T5-small` model on the aforementioned data\n",
    "3. Manually evaluate the outputs on test data\n",
    "4. Test the model in a complete pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a4cfcf",
   "metadata": {},
   "source": [
    "300k: (\"it is bad to pee\"->(\"bad\", \"to pee\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79047ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ailignment.datasets.moral_stories import get_moral_stories, make_action_classification_dataframe\n",
    "from ailignment.datasets import get_accuracy_metric, join_sentences, tokenize_and_split\n",
    "import pandas as pd\n",
    "import datasets\n",
    "import transformers\n",
    "import numpy as np\n",
    "from ailignment import sequence_classification\n",
    "\n",
    "pd.set_option('display.max_colwidth', 400)\n",
    "\n",
    "#transformers.logging.set_verbosity_warning()\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebd3dec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2s_data = pd.read_pickle(\"../data/moral_stories_proto_l2s.dat\")\n",
    "proto_data = pd.read_pickle(\"../data/moral_stories_proto_light.dat\")\n",
    "\n",
    "dataframe = proto_data.join(l2s_data[[\"norm_value\",\"norm_action\"]], how=\"inner\")\n",
    "test_frame = l2s_data.drop(proto_data.index).drop(\"__index_level_0__\",axis=1)\n",
    "# add random names to the test frame\n",
    "test_frame[\"actor_name\"] = dataframe[\"actor_name\"].sample(len(test_frame)).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f97f38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "name = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "167e2f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2216c4192044aa7b75c09755f896644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dddd605b883841d1a5b957b13c27144c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4005d3a68b644f60b3a6a3c9d37af479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6402bb8955244f738757268941da58d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef3a5eb221a948aa9a67d840cd86a6c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fix up huggingface dataset\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def tok_inp(x):\n",
    "    return tokenizer(x[\"norm_action\"],x[\"actor_name\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "def tok_out(x):\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        y = tokenizer(x[\"norm_story\"], padding=\"max_length\", truncation=True)\n",
    "    return y\n",
    "\n",
    "def preprocess(dataframe, test=False):\n",
    "    dataset = Dataset.from_pandas(dataframe)\n",
    "    dataset =  dataset.map(tok_inp, batched=True)\n",
    "    if not test:\n",
    "        labels = dataset.map(tok_out, batched=True)\n",
    "        dataset = dataset.add_column(\"labels\", labels[\"input_ids\"])\n",
    "    return dataset\n",
    "\n",
    "train, val = train_test_split(dataframe, test_size=0.1)\n",
    "\n",
    "train_data = preprocess(train)\n",
    "eval_data = preprocess(val)\n",
    "test_data = preprocess(test_frame, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7b2d8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
    "\n",
    "import torch\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"results/\",\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=50,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_steps=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "367dd851",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: actor_gender, value, norm_value, moral_consequence, intention, situation, __index_level_0__, moral_action, ID, norm_sentiment, actor_name, norm_action, norm_story, immoral_consequence, immoral_action, norm, norm_devalued.\n",
      "***** Running training *****\n",
      "  Num examples = 7600\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6046' max='19000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 6046/19000 39:04 < 1:23:44, 2.58 it/s, Epoch 3.18/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.001550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.000767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to results/checkpoint-1000\n",
      "Configuration saved in results/checkpoint-1000\\config.json\n",
      "Model weights saved in results/checkpoint-1000\\pytorch_model.bin\n",
      "tokenizer config file saved in results/checkpoint-1000\\tokenizer_config.json\n",
      "Special tokens file saved in results/checkpoint-1000\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: actor_gender, value, norm_value, moral_consequence, intention, situation, __index_level_0__, moral_action, ID, norm_sentiment, actor_name, norm_action, norm_story, immoral_consequence, immoral_action, norm, norm_devalued.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 845\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to results/checkpoint-2000\n",
      "Configuration saved in results/checkpoint-2000\\config.json\n",
      "Model weights saved in results/checkpoint-2000\\pytorch_model.bin\n",
      "tokenizer config file saved in results/checkpoint-2000\\tokenizer_config.json\n",
      "Special tokens file saved in results/checkpoint-2000\\special_tokens_map.json\n",
      "Saving model checkpoint to results/checkpoint-3000\n",
      "Configuration saved in results/checkpoint-3000\\config.json\n",
      "Model weights saved in results/checkpoint-3000\\pytorch_model.bin\n",
      "tokenizer config file saved in results/checkpoint-3000\\tokenizer_config.json\n",
      "Special tokens file saved in results/checkpoint-3000\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: actor_gender, value, norm_value, moral_consequence, intention, situation, __index_level_0__, moral_action, ID, norm_sentiment, actor_name, norm_action, norm_story, immoral_consequence, immoral_action, norm, norm_devalued.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 845\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to results/checkpoint-4000\n",
      "Configuration saved in results/checkpoint-4000\\config.json\n",
      "Model weights saved in results/checkpoint-4000\\pytorch_model.bin\n",
      "tokenizer config file saved in results/checkpoint-4000\\tokenizer_config.json\n",
      "Special tokens file saved in results/checkpoint-4000\\special_tokens_map.json\n",
      "Saving model checkpoint to results/checkpoint-5000\n",
      "Configuration saved in results/checkpoint-5000\\config.json\n",
      "Model weights saved in results/checkpoint-5000\\pytorch_model.bin\n",
      "tokenizer config file saved in results/checkpoint-5000\\tokenizer_config.json\n",
      "Special tokens file saved in results/checkpoint-5000\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: actor_gender, value, norm_value, moral_consequence, intention, situation, __index_level_0__, moral_action, ID, norm_sentiment, actor_name, norm_action, norm_story, immoral_consequence, immoral_action, norm, norm_devalued.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 845\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to results/checkpoint-6000\n",
      "Configuration saved in results/checkpoint-6000\\config.json\n",
      "Model weights saved in results/checkpoint-6000\\pytorch_model.bin\n",
      "tokenizer config file saved in results/checkpoint-6000\\tokenizer_config.json\n",
      "Special tokens file saved in results/checkpoint-6000\\special_tokens_map.json\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17172/116620518.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtokenizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m )\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\nikla\\workspace\\piep\\env\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1330\u001b[0m                         \u001b[0moptimizer_was_run\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscale_before\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mscale_after\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1332\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0moptimizer_was_run\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikla\\workspace\\piep\\env\\lib\\site-packages\\torch\\optim\\lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[1;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikla\\workspace\\piep\\env\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\nikla\\workspace\\piep\\env\\lib\\site-packages\\transformers\\optimization.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    356\u001b[0m                     \u001b[0mstep_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m                 \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m                 \u001b[1;31m# Just adding the square of the weights to the loss function is *not*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b2ad128",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/models/storifier\\config.json\n",
      "Model weights saved in ../data/models/storifier\\pytorch_model.bin\n",
      "tokenizer config file saved in ../data/models/storifier\\tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/storifier\\special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../data/models/storifier\\\\tokenizer_config.json',\n",
       " '../data/models/storifier\\\\special_tokens_map.json',\n",
       " '../data/models/storifier\\\\tokenizer.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../data/models/storifier\"\n",
    "model.save_pretrained(path)\n",
    "tokenizer.save_pretrained(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "078d081d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file results/checkpoint-4000/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading weights file results/checkpoint-4000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at results/checkpoint-4000/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"results/checkpoint-4000/\").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eeeb997b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actor_name</th>\n",
       "      <th>story</th>\n",
       "      <th>norm_action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7207</th>\n",
       "      <td>Adam</td>\n",
       "      <td>Adam cleans his arms only</td>\n",
       "      <td>only cleaning your arms.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9070</th>\n",
       "      <td>Tom</td>\n",
       "      <td>Tom does not eat food his parent has prepared</td>\n",
       "      <td>not eating food your parent has prepared.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>Ron</td>\n",
       "      <td>Ron betrays his friends confidence in he to others</td>\n",
       "      <td>betraying your friends confidence in you to others.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3080</th>\n",
       "      <td>Nancy</td>\n",
       "      <td>Nancy only thinks about herself when talking</td>\n",
       "      <td>only thinking about yourself when talking.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2766</th>\n",
       "      <td>Josh</td>\n",
       "      <td>Josh hurts animals if he love them</td>\n",
       "      <td>hurting animals if you love them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4928</th>\n",
       "      <td>Heather</td>\n",
       "      <td>Heather not cancels plans</td>\n",
       "      <td>not canceling plans.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actor_name                                               story  \\\n",
       "7207       Adam                           Adam cleans his arms only   \n",
       "9070        Tom       Tom does not eat food his parent has prepared   \n",
       "736         Ron  Ron betrays his friends confidence in he to others   \n",
       "3080      Nancy        Nancy only thinks about herself when talking   \n",
       "2766       Josh                  Josh hurts animals if he love them   \n",
       "4928    Heather                           Heather not cancels plans   \n",
       "\n",
       "                                              norm_action  \n",
       "7207                             only cleaning your arms.  \n",
       "9070            not eating food your parent has prepared.  \n",
       "736   betraying your friends confidence in you to others.  \n",
       "3080           only thinking about yourself when talking.  \n",
       "2766                    hurting animals if you love them.  \n",
       "4928                                 not canceling plans.  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run our test set\n",
    "hard_samples = [7207, 9070, 736, 3080, 2766, 4928]\n",
    "sample = test_frame.sample(10)\n",
    "sample = test_frame.loc[hard_samples]\n",
    "x = tokenizer(sample[\"norm_action\"].to_list(),sample[\"actor_name\"].to_list(), padding=\"max_length\", return_tensors=\"pt\")\n",
    "x = {k:v.cuda() for k,v in x.items()}\n",
    "y = model.generate(**x, do_sample=True, min_length=5, max_length=100, top_p=0.95, top_k=50, num_beams=10, temperature=1.0)\n",
    "sample[\"story\"] = tokenizer.batch_decode(y, skip_special_tokens=True)\n",
    "sample[[\"actor_name\",\"story\", \"norm_action\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da148a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
