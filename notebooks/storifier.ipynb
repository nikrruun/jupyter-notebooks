{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c9a3812",
   "metadata": {},
   "source": [
    "# Storifier-Transformer\n",
    "***\n",
    "For the `Moral Reasoning - Moral = Reasoning` experiment we need to exemplify the norm as an action:\n",
    "* Given a norm: \"It is bad to hurt someone\"\n",
    "* And an actor: \"Kevin\"\n",
    "* Using the `Learn2Split` model we get (`bad`,`hurting someone`)\n",
    "* We want: \"Kevin hurts someone\"\n",
    "\n",
    "In this notebook, I want to test whether `seq2seq` transformers can generate such sentences given the input pair of `norm_action` and `name`.\n",
    "\n",
    "Experiment outline:\n",
    "1. Take the handcrafted `norm_stories` from the prototype\n",
    "    1. We take the labeled subset as training data and the unlabeled are test\n",
    "2. Train a `T5-small` model on the aforementioned data\n",
    "3. Manually evaluate the outputs on test data\n",
    "4. Test the model in a complete pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79047ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ailignment.datasets.moral_stories import get_moral_stories, make_action_classification_dataframe\n",
    "from ailignment.datasets import get_accuracy_metric, join_sentences, tokenize_and_split\n",
    "import pandas as pd\n",
    "import datasets\n",
    "import transformers\n",
    "import numpy as np\n",
    "from ailignment import sequence_classification\n",
    "\n",
    "pd.set_option('display.max_colwidth', 400)\n",
    "\n",
    "#transformers.logging.set_verbosity_warning()\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebd3dec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2s_data = pd.read_pickle(\"../data/moral_stories_proto_l2s.dat\")\n",
    "proto_data = pd.read_pickle(\"../data/moral_stories_proto_light.dat\")\n",
    "\n",
    "dataframe = proto_data.join(l2s_data[[\"norm_value\",\"norm_action\"]], how=\"inner\")\n",
    "test_frame = l2s_data.drop(proto_data.index).drop(\"__index_level_0__\",axis=1)\n",
    "# add random names to the test frame\n",
    "test_frame[\"actor_name\"] = dataframe[\"actor_name\"].sample(len(test_frame)).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f97f38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "name = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "167e2f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10120fb33da74f27b691964f23698190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afeff9f16cdb496e823834995949dbd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e1b31fefd104a4dae48606eaf6d4998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b0c486cd5f42729b2f4e5276ccf5ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c58f5722f234f33a26f73dbb121397f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fix up huggingface dataset\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def tok_inp(x):\n",
    "    return tokenizer(x[\"norm_action\"],x[\"actor_name\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "def tok_out(x):\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        y = tokenizer(x[\"norm_story\"], padding=\"max_length\", truncation=True)\n",
    "    return y\n",
    "\n",
    "def preprocess(dataframe, test=False):\n",
    "    dataset = Dataset.from_pandas(dataframe)\n",
    "    dataset =  dataset.map(tok_inp, batched=True)\n",
    "    if not test:\n",
    "        labels = dataset.map(tok_out, batched=True)\n",
    "        dataset = dataset.add_column(\"labels\", labels[\"input_ids\"])\n",
    "    return dataset\n",
    "\n",
    "train, val = train_test_split(dataframe, test_size=0.1)\n",
    "\n",
    "train_data = preprocess(train)\n",
    "eval_data = preprocess(val)\n",
    "test_data = preprocess(test_frame, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7b2d8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
    "\n",
    "import torch\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"results/\",\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=50,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_steps=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "367dd851",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: norm_devalued, norm_action, moral_action, norm_value, ID, norm_story, norm_sentiment, intention, actor_gender, immoral_consequence, immoral_action, moral_consequence, situation, actor_name, norm, __index_level_0__, value.\n",
      "***** Running training *****\n",
      "  Num examples = 7600\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14740' max='19000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14740/19000 1:23:41 < 24:11, 2.93 it/s, Epoch 7.76/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.001914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.001112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.000927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.000747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to results/checkpoint-1000\n",
      "Configuration saved in results/checkpoint-1000\\config.json\n",
      "Model weights saved in results/checkpoint-1000\\pytorch_model.bin\n",
      "tokenizer config file saved in results/checkpoint-1000\\tokenizer_config.json\n",
      "Special tokens file saved in results/checkpoint-1000\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: norm_devalued, norm_action, moral_action, norm_value, ID, norm_story, norm_sentiment, intention, actor_gender, immoral_consequence, immoral_action, moral_consequence, situation, actor_name, norm, __index_level_0__, value.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 845\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to results/checkpoint-2000\n",
      "Configuration saved in results/checkpoint-2000\\config.json\n",
      "Model weights saved in results/checkpoint-2000\\pytorch_model.bin\n",
      "tokenizer config file saved in results/checkpoint-2000\\tokenizer_config.json\n",
      "Special tokens file saved in results/checkpoint-2000\\special_tokens_map.json\n",
      "Saving model checkpoint to results/checkpoint-3000\n",
      "Configuration saved in results/checkpoint-3000\\config.json\n",
      "Model weights saved in results/checkpoint-3000\\pytorch_model.bin\n",
      "tokenizer config file saved in results/checkpoint-3000\\tokenizer_config.json\n",
      "Special tokens file saved in results/checkpoint-3000\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: norm_devalued, norm_action, moral_action, norm_value, ID, norm_story, norm_sentiment, intention, actor_gender, immoral_consequence, immoral_action, moral_consequence, situation, actor_name, norm, __index_level_0__, value.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 845\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to results/checkpoint-4000\n",
      "Configuration saved in results/checkpoint-4000\\config.json\n",
      "Model weights saved in results/checkpoint-4000\\pytorch_model.bin\n",
      "tokenizer config file saved in results/checkpoint-4000\\tokenizer_config.json\n",
      "Special tokens file saved in results/checkpoint-4000\\special_tokens_map.json\n",
      "Saving model checkpoint to results/checkpoint-5000\n",
      "Configuration saved in results/checkpoint-5000\\config.json\n",
      "Model weights saved in results/checkpoint-5000\\pytorch_model.bin\n",
      "tokenizer config file saved in results/checkpoint-5000\\tokenizer_config.json\n",
      "Special tokens file saved in results/checkpoint-5000\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: norm_devalued, norm_action, moral_action, norm_value, ID, norm_story, norm_sentiment, intention, actor_gender, immoral_consequence, immoral_action, moral_consequence, situation, actor_name, norm, __index_level_0__, value.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 845\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to results/checkpoint-6000\n",
      "Configuration saved in results/checkpoint-6000\\config.json\n",
      "Model weights saved in results/checkpoint-6000\\pytorch_model.bin\n",
      "tokenizer config file saved in results/checkpoint-6000\\tokenizer_config.json\n",
      "Special tokens file saved in results/checkpoint-6000\\special_tokens_map.json\n",
      "Saving model checkpoint to results/checkpoint-7000\n",
      "Configuration saved in results/checkpoint-7000\\config.json\n",
      "Model weights saved in results/checkpoint-7000\\pytorch_model.bin\n",
      "tokenizer config file saved in results/checkpoint-7000\\tokenizer_config.json\n",
      "Special tokens file saved in results/checkpoint-7000\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: norm_devalued, norm_action, moral_action, norm_value, ID, norm_story, norm_sentiment, intention, actor_gender, immoral_consequence, immoral_action, moral_consequence, situation, actor_name, norm, __index_level_0__, value.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 845\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to results/checkpoint-8000\n",
      "Configuration saved in results/checkpoint-8000\\config.json\n",
      "Model weights saved in results/checkpoint-8000\\pytorch_model.bin\n",
      "tokenizer config file saved in results/checkpoint-8000\\tokenizer_config.json\n",
      "Special tokens file saved in results/checkpoint-8000\\special_tokens_map.json\n",
      "Saving model checkpoint to results/checkpoint-9000\n",
      "Configuration saved in results/checkpoint-9000\\config.json\n",
      "Model weights saved in results/checkpoint-9000\\pytorch_model.bin\n",
      "tokenizer config file saved in results/checkpoint-9000\\tokenizer_config.json\n",
      "Special tokens file saved in results/checkpoint-9000\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: norm_devalued, norm_action, moral_action, norm_value, ID, norm_story, norm_sentiment, intention, actor_gender, immoral_consequence, immoral_action, moral_consequence, situation, actor_name, norm, __index_level_0__, value.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 845\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to results/checkpoint-10000\n",
      "Configuration saved in results/checkpoint-10000\\config.json\n",
      "Model weights saved in results/checkpoint-10000\\pytorch_model.bin\n",
      "tokenizer config file saved in results/checkpoint-10000\\tokenizer_config.json\n",
      "Special tokens file saved in results/checkpoint-10000\\special_tokens_map.json\n",
      "Saving model checkpoint to results/checkpoint-11000\n",
      "Configuration saved in results/checkpoint-11000\\config.json\n",
      "Model weights saved in results/checkpoint-11000\\pytorch_model.bin\n",
      "tokenizer config file saved in results/checkpoint-11000\\tokenizer_config.json\n",
      "Special tokens file saved in results/checkpoint-11000\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: norm_devalued, norm_action, moral_action, norm_value, ID, norm_story, norm_sentiment, intention, actor_gender, immoral_consequence, immoral_action, moral_consequence, situation, actor_name, norm, __index_level_0__, value.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 845\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to results/checkpoint-12000\n",
      "Configuration saved in results/checkpoint-12000\\config.json\n",
      "Model weights saved in results/checkpoint-12000\\pytorch_model.bin\n",
      "tokenizer config file saved in results/checkpoint-12000\\tokenizer_config.json\n",
      "Special tokens file saved in results/checkpoint-12000\\special_tokens_map.json\n",
      "Saving model checkpoint to results/checkpoint-13000\n",
      "Configuration saved in results/checkpoint-13000\\config.json\n",
      "Model weights saved in results/checkpoint-13000\\pytorch_model.bin\n",
      "tokenizer config file saved in results/checkpoint-13000\\tokenizer_config.json\n",
      "Special tokens file saved in results/checkpoint-13000\\special_tokens_map.json\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: norm_devalued, norm_action, moral_action, norm_value, ID, norm_story, norm_sentiment, intention, actor_gender, immoral_consequence, immoral_action, moral_consequence, situation, actor_name, norm, __index_level_0__, value.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 845\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to results/checkpoint-14000\n",
      "Configuration saved in results/checkpoint-14000\\config.json\n",
      "Model weights saved in results/checkpoint-14000\\pytorch_model.bin\n",
      "tokenizer config file saved in results/checkpoint-14000\\tokenizer_config.json\n",
      "Special tokens file saved in results/checkpoint-14000\\special_tokens_map.json\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3836/116620518.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtokenizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m )\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\kiehne\\workspace\\moral-stories-notebook\\env\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1284\u001b[0m                         \u001b[0mtr_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1285\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1286\u001b[1;33m                     \u001b[0mtr_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1287\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_flos\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kiehne\\workspace\\moral-stories-notebook\\env\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   1795\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1796\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1797\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1799\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kiehne\\workspace\\moral-stories-notebook\\env\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kiehne\\workspace\\moral-stories-notebook\\env\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0b2ad128",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/models/storifier\\config.json\n",
      "Model weights saved in ../data/models/storifier\\pytorch_model.bin\n",
      "tokenizer config file saved in ../data/models/storifier\\tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/storifier\\special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../data/models/storifier\\\\tokenizer_config.json',\n",
       " '../data/models/storifier\\\\special_tokens_map.json',\n",
       " '../data/models/storifier\\\\tokenizer.json')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../data/models/storifier\"\n",
    "model.save_pretrained(path)\n",
    "tokenizer.save_pretrained(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "078d081d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file results/checkpoint-4000/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"t5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading weights file results/checkpoint-4000/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at results/checkpoint-4000/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"results/checkpoint-4000/\").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eeeb997b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actor_name</th>\n",
       "      <th>story</th>\n",
       "      <th>norm_action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7207</th>\n",
       "      <td>Dave</td>\n",
       "      <td>Dave cleans his arms</td>\n",
       "      <td>only cleaning your arms.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9070</th>\n",
       "      <td>Luke</td>\n",
       "      <td>Luke does not eat food his parent has prepared</td>\n",
       "      <td>not eating food your parent has prepared.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>John</td>\n",
       "      <td>John betrays his friends confidence in he to others</td>\n",
       "      <td>betraying your friends confidence in you to others.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3080</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Bob thinks about himself when talking</td>\n",
       "      <td>only thinking about yourself when talking.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2766</th>\n",
       "      <td>Sam</td>\n",
       "      <td>Sam hurts animals if he love them</td>\n",
       "      <td>hurting animals if you love them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4928</th>\n",
       "      <td>Frank</td>\n",
       "      <td>Frank n's cancels plans</td>\n",
       "      <td>not canceling plans.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actor_name                                                story  \\\n",
       "7207       Dave                                 Dave cleans his arms   \n",
       "9070       Luke       Luke does not eat food his parent has prepared   \n",
       "736        John  John betrays his friends confidence in he to others   \n",
       "3080        Bob                Bob thinks about himself when talking   \n",
       "2766        Sam                    Sam hurts animals if he love them   \n",
       "4928      Frank                              Frank n's cancels plans   \n",
       "\n",
       "                                              norm_action  \n",
       "7207                             only cleaning your arms.  \n",
       "9070            not eating food your parent has prepared.  \n",
       "736   betraying your friends confidence in you to others.  \n",
       "3080           only thinking about yourself when talking.  \n",
       "2766                    hurting animals if you love them.  \n",
       "4928                                 not canceling plans.  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run our test set\n",
    "hard_samples = [7207, 9070, 736, 3080, 2766, 4928]\n",
    "sample = test_frame.sample(10)\n",
    "sample = test_frame.loc[hard_samples]\n",
    "x = tokenizer(sample[\"norm_action\"].to_list(),sample[\"actor_name\"].to_list(), padding=\"max_length\", return_tensors=\"pt\")\n",
    "x = {k:v.cuda() for k,v in x.items()}\n",
    "y = model.generate(**x, do_sample=False, min_length=1, max_length=100, top_p=0.95, top_k=50, num_beams=10, temperature=1.0)\n",
    "sample[\"story\"] = tokenizer.batch_decode(y, skip_special_tokens=True)\n",
    "sample[[\"actor_name\",\"story\", \"norm_action\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da148a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
