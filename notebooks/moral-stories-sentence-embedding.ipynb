{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27c8dd50",
   "metadata": {},
   "source": [
    "## Task:\n",
    "***\n",
    "We want to get a better split of the Moral Stories dataset. Idea: Lets compute sentence embeddings and try to find train/test splits with high degree of separation.\n",
    "\n",
    "Approach:\n",
    "* Get embedding vectors of norm_actions, e.g. \"hurting somebody\".\n",
    "* Get clusters of the vectors\n",
    "* Do splitting based on the clusters instead of based on single norms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4154749",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b65379c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def assign_norm_clusters(dataframe, embedding_model='all-distilroberta-v1'):\n",
    "    '''\n",
    "    Clusters the \"norm_action\" in the given dataframe according\n",
    "    to sentence_embeddings from transformer models.\n",
    "    A new column \"cluster\" will be assigned to the dataframe.\n",
    "    KMeans will be employed.\n",
    "    '''\n",
    "    model = SentenceTransformer(embedding_model)\n",
    "    embeddings = model.encode(dataframe[\"norm_action\"], show_progress_bar=True)\n",
    "    clustering = KMeans(n_clusters=100, init=\"k-means++\", max_iter=300, n_init=5)\n",
    "    dataframe[\"cluster\"] = clustering.fit_predict(embeddings)\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d792b7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "import transformers\n",
    "\n",
    "import torch\n",
    "\n",
    "from ailignment.datasets.util import get_accuracy_metric\n",
    "from ailignment.datasets.moral_stories import make_action_classification_dataframe, get_random_value_dataset\n",
    "\n",
    "from ailignment.training import sequence_classification\n",
    "\n",
    "pd.set_option('display.max_colwidth', 400)\n",
    "dataframe = pd.read_pickle(\"../data/moral_stories_proto_l2s.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f42f22ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('all-distilroberta-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9d1ce120",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 77 172 108 139 226 131 107 110  94 165  94 150 234  85 153 130 110 116\n",
      " 141 143 120 115  96 160 102  84 115 136 100  85 102 136 155  86 134 189\n",
      "  49 151  71 108 192  66  96 121 118 149  93  90  48 146  53  58 104  93\n",
      " 122 157 185 151  65 111 148 100 115  73 199 103  48 115  77  88 145 109\n",
      " 141  87 158  70  48  97  86 111 106 248  74 111 116 131 250 111  89 129\n",
      "  85 123 106 118 153 166 159 161 109 136]\n",
      "----------\n",
      "108          taking advantage of a friend's generosity.\n",
      "170                     doing favors for close friends.\n",
      "182      thanking friends for inviting you to do things\n",
      "191               wanting to be friends with murderers.\n",
      "194                           beg strangers for treats.\n",
      "                              ...                      \n",
      "11441                        doing favors for a friend.\n",
      "11533            outing your friends after their death.\n",
      "11600                   giving a friend a place to stay\n",
      "11619                            abadoning you friends.\n",
      "11792                         standing up for a friend.\n",
      "Name: norm_action, Length: 77, dtype: object\n",
      "----------\n",
      "79                      leaving pets unattended in a car\n",
      "110                                   making a cat hiss.\n",
      "146      letting young children near unpredictable dogs.\n",
      "347          just letting stray dogs wander the streets.\n",
      "354                           lighting your cat on fire.\n",
      "                              ...                       \n",
      "11537                letting your child's animal suffer.\n",
      "11612                                stabbing a hamster.\n",
      "11755                            abandoning your animal.\n",
      "11865             keeping your dog on your own property.\n",
      "11885                                  hurting your dog.\n",
      "Name: norm_action, Length: 172, dtype: object\n",
      "----------\n",
      "144                crushing children's imaginations.\n",
      "276               running because it's good for you.\n",
      "524                         trying fooling yourself.\n",
      "682                            appreciating history.\n",
      "737                                  discriminating.\n",
      "                            ...                     \n",
      "11773              crushing children's imaginations.\n",
      "11808          spoiling twists in movies for people.\n",
      "11845                             partying too much.\n",
      "11852                           freaking people out.\n",
      "11855    expecting everyone to find something funny.\n",
      "Name: norm_action, Length: 108, dtype: object\n",
      "----------\n",
      "16                                not talking to your in-laws.\n",
      "43               losing something that belongs to your family.\n",
      "44                                   being rude to your family\n",
      "91       being upset at your deceased family member's partner.\n",
      "301                               turning down family members.\n",
      "                                 ...                          \n",
      "11899            upseting your family by taking your own life.\n",
      "11931                                  abusing your loved ones\n",
      "11942                                embarrassing your family.\n",
      "11986                      getting angry with their relatives.\n",
      "11988                 discussing things over with your family.\n",
      "Name: norm_action, Length: 139, dtype: object\n",
      "----------\n",
      "88                                      physically hitting a relative.\n",
      "132                                                 not biting people.\n",
      "176                                                      hitting women\n",
      "233                      accusing someone of something they didn't do.\n",
      "234                                          sexually abusing someone.\n",
      "                                     ...                              \n",
      "11647                    throwing someone's possessions on the ground.\n",
      "11698                                     kicking people in the groin.\n",
      "11721                                      seeking revenge on someone.\n",
      "11828    letting someone consume something that is possibly dangerous.\n",
      "11888                                       abusing a martial partner.\n",
      "Name: norm_action, Length: 226, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans, DBSCAN, OPTICS\n",
    "\n",
    "clustering = KMeans(n_clusters=100, init=\"k-means++\", max_iter=300, n_init=5)\n",
    "#clustering = DBSCAN(eps=2.7, min_samples=2, metric=\"euclidean\")\n",
    "#clustering = OPTICS()\n",
    "\n",
    "dataframe[\"cluster\"] = clustering.fit_predict(embeddings)\n",
    "\n",
    "print(np.unique(dataframe[\"cluster\"], return_counts=True)[1])\n",
    "g = dataframe.groupby(\"cluster\", axis=0)\n",
    "for i in [-1,0,1,2,3,4]:\n",
    "    if i in g.groups:\n",
    "        print(\"-\"*10)\n",
    "        print(g.get_group(i)[\"norm_action\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "35a5e709",
   "metadata": {},
   "outputs": [],
   "source": [
    "    immoral_df = dataframe.drop([\"moral_action\", \"moral_consequence\"], axis=1)\n",
    "    moral_df = dataframe.drop([\"immoral_action\", \"immoral_consequence\"], axis=1)\n",
    "    # rename columns\n",
    "    moral_df.rename(columns={\"moral_action\":\"action\",\n",
    "                            \"moral_consequence\":\"consequence\"},\n",
    "                    inplace=True)\n",
    "    immoral_df.rename(columns={\"immoral_action\":\"action\",\n",
    "                            \"immoral_consequence\":\"consequence\"},\n",
    "                    inplace=True)\n",
    "    # add labels\n",
    "    immoral_df[\"labels\"] = 0\n",
    "    moral_df[\"labels\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c1efacb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "gss = GroupShuffleSplit(1, test_size=0.2)\n",
    "xi, yi = list(gss.split(moral_df, groups=dataframe[\"cluster\"]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e289301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([moral_df.iloc[xi], immoral_df.iloc[xi]], ignore_index=True).sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "58ee716d",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_values=None\n",
    "bad_values=None\n",
    "p=0.5\n",
    "top_n=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ffaac89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    if good_values is None or bad_values is None:\n",
    "        # get frequent norm judgments\n",
    "        top_negative = dataframe.groupby(\"norm_sentiment\").get_group(\"NEGATIVE\")[\"norm_value\"].value_counts()\n",
    "        top_positive = dataframe.groupby(\"norm_sentiment\").get_group(\"POSITIVE\")[\"norm_value\"].value_counts()\n",
    "        good_values = top_positive[:top_n].index\n",
    "        bad_values = top_negative[:top_n].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9435a591",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ailignment.datasets.moral_stories import randomize_norm_value, flip_norm\n",
    "random_values = dataframe.copy()\n",
    "random_values = random_values.apply(randomize_norm_value(good_values, bad_values), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "afc95b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "flip_all = flip_norm(good_values, bad_values, 1.1) # a function that flips everything\n",
    "flip_none = flip_norm(good_values, bad_values, -1.1) # a function that flips nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d16c6238",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_cluster(p):\n",
    "    def t(data):\n",
    "        if np.random.rand()<=p:\n",
    "            return data.apply(flip_all, axis=1)\n",
    "        return data.apply(flip_none, axis=1)\n",
    "    return t\n",
    "groups = random_values.groupby(\"cluster\").apply(flip_cluster(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fe0d8554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     6542\n",
       "False    5454\n",
       "Name: flipped, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups[\"flipped\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "450a0154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.0+cu102'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad69b9cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
