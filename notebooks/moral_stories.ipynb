{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a64ba63",
   "metadata": {},
   "source": [
    "# Loading the `Moral-Stories` dataset\n",
    "***\n",
    "The dataset and code can be found <a href=\"https://github.com/demelin/moral_stories\">here</a>.\\\n",
    "The authors provide 12k unique norms and, for some reason, additional 700k variations of the same norms, just with NaN fields every now and then. Zero additional information, but maybe I am overlooking something here?\n",
    "* Might be for different tasks? But then they only provide a single label which is always 1 for any NaN rows..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc517ac3",
   "metadata": {},
   "source": [
    "# Sample task: Action classification\n",
    "***\n",
    "For starters, let's reproduce a task from the paper:\n",
    "* Given an action, predict whether it is moral or immoral.\n",
    "* For simplicity, we do not use the splits introduced in the paper, but rather random splitting\n",
    "\n",
    "We start by loading the data as a `pandas.DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfcfee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ailignment.datasets.moral_stories import get_moral_stories, make_action_classification_dataframe\n",
    "from ailignment.datasets import get_accuracy_metric, join_sentences, tokenize_and_split\n",
    "from transformers import TrainingArguments\n",
    "import pandas as pd\n",
    "\n",
    "dataframe = get_moral_stories()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef18416",
   "metadata": {},
   "source": [
    "## Task 1: Action only\n",
    "***\n",
    "We'll only give single sentences to the model for now. Let's start by feeding the actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6592a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "test_split = 0.2\n",
    "batch_size = 8\n",
    "model = \"distilbert-base-uncased\"\n",
    "#model = \"albert-base-v2\"\n",
    "action_dataframe = make_action_classification_dataframe(dataframe)\n",
    "input_columns = [\"action\", \"consequence\"]\n",
    "action_dataframe[\"task_input\"] = join_sentences(action_dataframe, input_columns, \" \")\n",
    "dataset = datasets.Dataset.from_pandas(action_dataframe)\n",
    "dataset = dataset.train_test_split(test_size=test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9853e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_all(tokenizer):\n",
    "    return tokenize_and_split(dataset, tokenizer, \"task_input\")\n",
    "def data_small(tokenizer):\n",
    "    train, test = data_all(tokenizer)\n",
    "    train = train.shuffle(seed=42).select(range(500))\n",
    "    test = test.shuffle(seed=42).select(range(500))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa85948",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"results/\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=12,\n",
    "    per_device_eval_batch_size=12,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=5,\n",
    "    save_steps=1000,\n",
    "    save_total_limit=2,\n",
    "    evaluation_strategy=\"epoch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75230e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "transformers.logging.set_verbosity_warning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40443b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ailignment import sequence_classification\n",
    "r = sequence_classification(data_small, model, get_accuracy_metric(), training_args)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce840a5",
   "metadata": {},
   "source": [
    "# WIP: Get score output from LM\n",
    "***\n",
    "Question: Is there a better way to sample from generated LM outputs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e617675",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoModelForSequenceClassification, DistilBertTokenizerFast,\n",
    "     Trainer, TrainingArguments, AutoModelWithLMHead, AutoTokenizer,\n",
    ")\n",
    "import torch\n",
    "\n",
    "model = \"distilbert-base-uncased\"\n",
    "model = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "model = AutoModelWithLMHead.from_pretrained(model)\n",
    "\n",
    "prompt = \"Today the weather is really nice and I am planning on \"\n",
    "inputs = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n",
    "\n",
    "prompt_length = len(tokenizer.decode(inputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True))\n",
    "outputs = model.generate(inputs, max_length=250, do_sample=False, top_p=0.95, top_k=60,\n",
    "                        return_dict_in_generate=True, output_attentions=False,\n",
    "                        output_hidden_states=True, output_scores=True)\n",
    "#generated = prompt + tokenizer.decode(outputs[0])[prompt_length:]\n",
    "\n",
    "p = torch.softmax(outputs.scores[0], dim=1)\n",
    "\n",
    "print(p.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87a84ed",
   "metadata": {},
   "source": [
    "# WIP: Data augmentation with NER\n",
    "***\n",
    "Idea: Use Named entity recognition to find and replace persons etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c818fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ailignment.datasets.moral_stories import get_moral_stories, make_action_classification_dataframe\n",
    "from ailignment import join_sentences, tokenize_and_split, get_accuracy_metric\n",
    "dataframe = get_moral_stories()\n",
    "columns = dataframe.columns[1:]\n",
    "print(\"Running NER on columns\", columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b146a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = join_sentences(dataframe ,columns, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4beffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "ner_pipe = nlp.pipe(tqdm(texts), disable=['tagger', 'parser', 'attribute_ruler', 'lemmatizer'])\n",
    "docs = [x for x in ner_pipe]\n",
    "\n",
    "displacy.render(docs[0], style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61607f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_frequent_entity(doc, entity=\"PERSON\", n=1):\n",
    "    '''\n",
    "    Returns the highest number of occurences of an\n",
    "    entity in the NER doc.\n",
    "    '''\n",
    "    occurences = [(x.text, x.label_) for x in doc.ents if x.label_ == entity]\n",
    "    c = Counter(occurences)\n",
    "    ents = []\n",
    "    for item, count in c.most_common(n):\n",
    "        ents.append([x for x in doc.ents if (x.text, x.label_) == item])\n",
    "    \n",
    "    if n == 1 and len(ents) != 0:\n",
    "        ents = ents[0]\n",
    "    return ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965139d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "persons = [get_frequent_entity(x, \"PERSON\",n=1) for x in docs]\n",
    "# we are interested in the simplest case, where the NER found\n",
    "# exactly 6 matches\n",
    "matches = [x for x in persons if len(x) == 6]\n",
    "print(f\"Found {len(matches)} matches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56082bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = matches[0]\n",
    "displacy.render(m[0].doc, \"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded8d9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_entity(ents, s):\n",
    "    '''\n",
    "    Replaces all occurences of entities in `ents` with `s`.\n",
    "    `ents` is a list of entities as returned by `doc.ents`\n",
    "    from an NER pipeline, they need to be from the same doc!\n",
    "    '''\n",
    "    offset = 0\n",
    "    text = ents[0].doc.text\n",
    "    new_text = \"\"\n",
    "    for ent in ents:\n",
    "        start = ent.start_char\n",
    "        end = ent.end_char\n",
    "        left = text[offset:start]\n",
    "        new_text += left + s\n",
    "        offset = end\n",
    "    new_text += text[offset:]\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae19b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_docs = [replace_entity(m, \"Niklas\").split(\"\\n\") for m in matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beee911a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_docs = [m[0].doc.text.split(\"\\n\") for m in matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863d1fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_replaced = pd.DataFrame(n_docs)\n",
    "dataframe_replaced.columns = columns\n",
    "dataframe_replaced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1896b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "test_split = 0.2\n",
    "batch_size = 8\n",
    "\n",
    "action_dataframe = make_action_classification_dataframe(dataframe_replaced)\n",
    "\n",
    "input_columns = [\"action\"]\n",
    "action_dataframe[\"task_input\"] = join_sentences(action_dataframe, input_columns, \" \")\n",
    "dataset = datasets.Dataset.from_pandas(action_dataframe)\n",
    "dataset = dataset.train_test_split(test_size=test_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5b78c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification, DistilBertTokenizerFast,\n",
    "     Trainer, TrainingArguments, AutoModelWithLMHead, AutoTokenizer,\n",
    ")\n",
    "import torch\n",
    "\n",
    "model = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model)\n",
    "\n",
    "train_data, test_data = tokenize_and_split(dataset, tokenizer, \"task_input\")\n",
    "\n",
    "# for prototyping, optional\n",
    "small_train_data = train_data.shuffle(seed=42).select(range(1000))\n",
    "small_test_data = test_data.shuffle(seed=42).select(range(1000))\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"results/\",\n",
    "    num_train_epochs=5,              # total number of training epochs\n",
    "    per_device_train_batch_size=8,  # batch size per device during training\n",
    "    per_device_eval_batch_size=8,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=50,                # how often to log\n",
    "    save_steps=1000,\n",
    "    save_total_limit=0,\n",
    "    evaluation_strategy=\"epoch\",     # when to run evaluation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22e0723",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=small_train_data,   # training dataset\n",
    "    eval_dataset=small_test_data,     # evaluation dataset\n",
    "    compute_metrics=get_accuracy_metric,     # code to run accuracy metric\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebbeaab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1711b948",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gender_guesser.detector import Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fd8975",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6774cae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.get_gender(\"Jamie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff68cec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f460d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.rand(40000,20000).cuda()\n",
    "while True:\n",
    "    a += 1\n",
    "    a -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4a88fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
