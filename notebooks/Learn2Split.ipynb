{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "278cc8d4",
   "metadata": {},
   "source": [
    "# Learning to split\n",
    "***\n",
    "Is it possible to teach a model to split a rule-of-thumb into action and judgement?\\\n",
    "Task:\n",
    "* Load and parse the Social-Chem-101 dataset consisting of ~300k rules of thumb, which were manually split into action and judgment\n",
    "* Train a seq2seq model on generating the sentence judgement + action from a given rot\n",
    "* Use the model to split the complete moral stories dataset, probably in another notebook though!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02fd8f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "pd.set_option('display.max_colwidth', 400)\n",
    "\n",
    "from ailignment.datasets import get_social_chem101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d3abc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rot-judgment</th>\n",
       "      <th>rot</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>235665</th>\n",
       "      <td>It's okay.</td>\n",
       "      <td>It is ok to express your feelings.</td>\n",
       "      <td>expressing your feelings.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93605</th>\n",
       "      <td>bad.</td>\n",
       "      <td>It is bad to be a freeloader</td>\n",
       "      <td>being a freeloader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53588</th>\n",
       "      <td>You can't.</td>\n",
       "      <td>You can't expect your partner to stay with you.</td>\n",
       "      <td>expecting your partner to stay with you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268972</th>\n",
       "      <td>It's good.</td>\n",
       "      <td>It's good to be honest.</td>\n",
       "      <td>being honest.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199902</th>\n",
       "      <td>It is wrong.</td>\n",
       "      <td>It is wrong to be overbearing in your adult sons life.</td>\n",
       "      <td>being overbearing in your adult sons life.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220092</th>\n",
       "      <td>should not.</td>\n",
       "      <td>You should not be wasteful.</td>\n",
       "      <td>being wasteful.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75376</th>\n",
       "      <td>should.</td>\n",
       "      <td>You should apologize to someone if you've hurt them.</td>\n",
       "      <td>apologizing to someone if you've hurt them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95345</th>\n",
       "      <td>You should.</td>\n",
       "      <td>You should be able to do whatever activity you want</td>\n",
       "      <td>being able to do whatever activity you want</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91165</th>\n",
       "      <td>should.</td>\n",
       "      <td>You should not use the pictures of others to gratify yourself without consent.</td>\n",
       "      <td>not using the pictures of others to gratify yourself without consent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242154</th>\n",
       "      <td>It's not okay.</td>\n",
       "      <td>It's not okay to over exert yourself and burn yourself out.</td>\n",
       "      <td>over exerting yourself and burning yourself out.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          rot-judgment  \\\n",
       "235665      It's okay.   \n",
       "93605             bad.   \n",
       "53588       You can't.   \n",
       "268972      It's good.   \n",
       "199902    It is wrong.   \n",
       "...                ...   \n",
       "220092     should not.   \n",
       "75376          should.   \n",
       "95345      You should.   \n",
       "91165          should.   \n",
       "242154  It's not okay.   \n",
       "\n",
       "                                                                                   rot  \\\n",
       "235665                                              It is ok to express your feelings.   \n",
       "93605                                                     It is bad to be a freeloader   \n",
       "53588                                  You can't expect your partner to stay with you.   \n",
       "268972                                                         It's good to be honest.   \n",
       "199902                          It is wrong to be overbearing in your adult sons life.   \n",
       "...                                                                                ...   \n",
       "220092                                                     You should not be wasteful.   \n",
       "75376                             You should apologize to someone if you've hurt them.   \n",
       "95345                              You should be able to do whatever activity you want   \n",
       "91165   You should not use the pictures of others to gratify yourself without consent.   \n",
       "242154                     It's not okay to over exert yourself and burn yourself out.   \n",
       "\n",
       "                                                                       action  \n",
       "235665                                              expressing your feelings.  \n",
       "93605                                                      being a freeloader  \n",
       "53588                                expecting your partner to stay with you.  \n",
       "268972                                                          being honest.  \n",
       "199902                             being overbearing in your adult sons life.  \n",
       "...                                                                       ...  \n",
       "220092                                                        being wasteful.  \n",
       "75376                             apologizing to someone if you've hurt them.  \n",
       "95345                             being able to do whatever activity you want  \n",
       "91165   not using the pictures of others to gratify yourself without consent.  \n",
       "242154                       over exerting yourself and burning yourself out.  \n",
       "\n",
       "[64 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_social_chem101().sample(100)\n",
    "# do some data cleaning\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# add punctuation to each rot-judgment\n",
    "data[\"rot-judgment\"] = data[\"rot-judgment\"].apply(lambda x: x if x[-1] in \".!\" else x+\".\")\n",
    "\n",
    "data[\"targets\"] = data[\"rot-judgment\"] + \" \" + data[\"action\"]\n",
    "\n",
    "data[[\"rot-judgment\", \"rot\", \"action\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63fc39f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the NLI model and its tokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "name = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c0c9c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d8be359220b4c82a4397a2c2e1ba64b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94df6b721f134a33b01ab5fd66547b03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a54cce749c204982af2ee0418a01d8ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcea527c9f474165a6acfdfb689d8e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fix up huggingface dataset\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def tok_inp(x):\n",
    "    return tokenizer(x[\"rot\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "def tok_out(x):\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        y = tokenizer(x[\"targets\"], padding=\"max_length\", truncation=True)\n",
    "    return y\n",
    "\n",
    "def preprocess(dataframe):\n",
    "    dataset = Dataset.from_pandas(dataframe)\n",
    "    dataset =  dataset.map(tok_inp, batched=True)\n",
    "    labels = dataset.map(tok_out, batched=True)\n",
    "    dataset = dataset.add_column(\"labels\", labels[\"input_ids\"])\n",
    "    return dataset\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.1)\n",
    "\n",
    "train_data = preprocess(train)\n",
    "eval_data = preprocess(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9698b447",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
    "\n",
    "import torch\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"results/garbo/\",\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=50,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_steps=10000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cde2084",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: action-char-involved, rot-categorization, rot-judgment, __index_level_0__, breakdown-worker-id, action-moral-judgment, rot, action, area, action-legal, rot-char-targeting, rot-worker-id, m, situation, characters, rot-moral-foundations, situation-short-id, targets, rot-bad, n-characters, action-agree, rot-id, action-pressure, split, rot-agree, action-hypothetical, action-agency.\n",
      "***** Running training *****\n",
      "  Num examples = 57\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 80\n",
      "/home/kiehne/workspace/jupyter-notebooks/env/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/80 00:07 < 00:10, 4.31 it/s, Epoch 4/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>16.666628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>16.472795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>16.154345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>15.696165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: action-char-involved, rot-categorization, rot-judgment, __index_level_0__, breakdown-worker-id, action-moral-judgment, rot, action, area, action-legal, rot-char-targeting, rot-worker-id, m, situation, characters, rot-moral-foundations, situation-short-id, targets, rot-bad, n-characters, action-agree, rot-id, action-pressure, split, rot-agree, action-hypothetical, action-agency.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: action-char-involved, rot-categorization, rot-judgment, __index_level_0__, breakdown-worker-id, action-moral-judgment, rot, action, area, action-legal, rot-char-targeting, rot-worker-id, m, situation, characters, rot-moral-foundations, situation-short-id, targets, rot-bad, n-characters, action-agree, rot-id, action-pressure, split, rot-agree, action-hypothetical, action-agency.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: action-char-involved, rot-categorization, rot-judgment, __index_level_0__, breakdown-worker-id, action-moral-judgment, rot, action, area, action-legal, rot-char-targeting, rot-worker-id, m, situation, characters, rot-moral-foundations, situation-short-id, targets, rot-bad, n-characters, action-agree, rot-id, action-pressure, split, rot-agree, action-hypothetical, action-agency.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: action-char-involved, rot-categorization, rot-judgment, __index_level_0__, breakdown-worker-id, action-moral-judgment, rot, action, area, action-legal, rot-char-targeting, rot-worker-id, m, situation, characters, rot-moral-foundations, situation-short-id, targets, rot-bad, n-characters, action-agree, rot-id, action-pressure, split, rot-agree, action-hypothetical, action-agency.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 7\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9005/3114919856.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/workspace/jupyter-notebooks/env/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1282\u001b[0m                         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m                     \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_flos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/jupyter-notebooks/env/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1787\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1789\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/jupyter-notebooks/env/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   1819\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1820\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1821\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1822\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1823\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/jupyter-notebooks/env/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/jupyter-notebooks/env/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/jupyter-notebooks/env/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/jupyter-notebooks/env/lib/python3.9/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1054\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1067\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f448f652",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/models/learn_to_split\\config.json\n",
      "Model weights saved in ../data/models/learn_to_split\\pytorch_model.bin\n",
      "tokenizer config file saved in ../data/models/learn_to_split\\tokenizer_config.json\n",
      "Special tokens file saved in ../data/models/learn_to_split\\special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('../data/models/learn_to_split\\\\tokenizer_config.json',\n",
       " '../data/models/learn_to_split\\\\special_tokens_map.json',\n",
       " '../data/models/learn_to_split\\\\tokenizer.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../data/models/learn_to_split\"\n",
    "model.save_pretrained(path)\n",
    "tokenizer.save_pretrained(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8156df",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer(\"You should not. hurting your siblings.\", add_special_tokens=True)[\"input_ids\"]\n",
    "print(tokens)\n",
    "print(tokenizer.decode(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b1f0ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nikla\\workspace\\piep\\env\\lib\\site-packages\\torch\\_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ..\\aten\\src\\ATen\\native\\BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rot</th>\n",
       "      <th>split</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>291372</th>\n",
       "      <td>It is appropriate to contact child services if you know of a child being mentally, physically, or sexually abused.</td>\n",
       "      <td>It is appropriate. contacting child services if you know of a child being mentally, physically, or sexually abused.</td>\n",
       "      <td>contacting child services if you know of a child being mentally, physically, or sexually abused.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291975</th>\n",
       "      <td>It's expected that family members should stick together.</td>\n",
       "      <td>It's expected. family members sticking together.</td>\n",
       "      <td>sticking together with family members.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270432</th>\n",
       "      <td>If you think you're sick, you should see a doctor.</td>\n",
       "      <td>should. seeing a doctor if you think you're sick</td>\n",
       "      <td>seeing a doctor when you think you're sick.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216267</th>\n",
       "      <td>It's better to get a job after high school and not head straight to college.</td>\n",
       "      <td>It's better. getting a job after high school and not head straight to college.</td>\n",
       "      <td>getting a job after high school and not heading straight to college.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287788</th>\n",
       "      <td>It's okay to be annoyed when it takes the repair shop a long time to get you taken care of.</td>\n",
       "      <td>It's okay. being annoyed when it takes the repair shop a long time to get you taken care of.</td>\n",
       "      <td>being annoyed when it takes the repair shop a long time to get you taken care of.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                       rot  \\\n",
       "291372  It is appropriate to contact child services if you know of a child being mentally, physically, or sexually abused.   \n",
       "291975                                                            It's expected that family members should stick together.   \n",
       "270432                                                                  If you think you're sick, you should see a doctor.   \n",
       "216267                                        It's better to get a job after high school and not head straight to college.   \n",
       "287788                         It's okay to be annoyed when it takes the repair shop a long time to get you taken care of.   \n",
       "\n",
       "                                                                                                                      split  \\\n",
       "291372  It is appropriate. contacting child services if you know of a child being mentally, physically, or sexually abused.   \n",
       "291975                                                                     It's expected. family members sticking together.   \n",
       "270432                                                                     should. seeing a doctor if you think you're sick   \n",
       "216267                                       It's better. getting a job after high school and not head straight to college.   \n",
       "287788                         It's okay. being annoyed when it takes the repair shop a long time to get you taken care of.   \n",
       "\n",
       "                                                                                                  action  \n",
       "291372  contacting child services if you know of a child being mentally, physically, or sexually abused.  \n",
       "291975                                                            sticking together with family members.  \n",
       "270432                                                       seeing a doctor when you think you're sick.  \n",
       "216267                              getting a job after high school and not heading straight to college.  \n",
       "287788                 being annoyed when it takes the repair shop a long time to get you taken care of.  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_samples = [291372, 291975, 270432, 216267, 287788 ]\n",
    "sample = data.sample(10).copy()\n",
    "sample = data.loc[hard_samples]\n",
    "x = tokenizer(sample[\"rot\"].to_list(), padding=\"max_length\", return_tensors=\"pt\")\n",
    "x = {k:v.cuda() for k,v in x.items()}\n",
    "y = model.generate(**x, do_sample=True, min_length=1, max_length=100, top_p=0.95, top_k=50, num_beams=10, temperature=1.0)\n",
    "sample[\"split\"] = tokenizer.batch_decode(y, skip_special_tokens=True)\n",
    "sample[[\"rot\",\"split\", \"action\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4926957",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"../data/models/learn_to_split/\").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efd6dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
