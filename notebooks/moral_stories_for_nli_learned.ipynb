{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2063a2e",
   "metadata": {},
   "source": [
    "# Preparing Moral Stories for NLI with Learn2Split\n",
    "***\n",
    "Two steps to be done:\n",
    "1. Split the norms in the Moral Stories dataset into values and actions\n",
    "2. Extract the names of the actors\n",
    "3. Make stories from actions and actor names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca95f7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ailignment.datasets.moral_stories import get_moral_stories, make_action_classification_dataframe\n",
    "from ailignment.datasets import get_accuracy_metric, join_sentences, tokenize_and_split\n",
    "import pandas as pd\n",
    "import datasets\n",
    "import transformers\n",
    "import numpy as np\n",
    "from ailignment import sequence_classification\n",
    "\n",
    "pd.set_option('display.max_colwidth', 400)\n",
    "\n",
    "#transformers.logging.set_verbosity_warning()\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78ddbc9",
   "metadata": {},
   "source": [
    "## Applying Learn2Split\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03b4079",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = get_moral_stories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e854396",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "name = \"../data/models/learn_to_split\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(name).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268e254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def parse_split(x):\n",
    "    if \".\" in x:\n",
    "        value, action = x.split(\".\",1)\n",
    "    else:\n",
    "        value, action = x.split(\" \", 1)\n",
    "    action = action.strip()\n",
    "    return {\"action\": action, \"value\":value}\n",
    "\n",
    "def split(x):\n",
    "    inputs = tokenizer(x[\"norm\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    inputs = {k:v.cuda() for k,v in inputs.items()}\n",
    "    out = model.generate(**inputs, do_sample=True, min_length=1, max_length=100, top_p=0.95, top_k=50, \n",
    "                         num_beams=1, temperature=1.0)\n",
    "    x[\"l2s_output\"] = tokenizer.batch_decode(out, skip_special_tokens=True)\n",
    "    pairs = pd.DataFrame.from_records([parse_split(y) for y in x[\"l2s_output\"]])\n",
    "    \n",
    "    x[\"norm_action\"] = pairs[\"action\"].to_list()\n",
    "    x[\"norm_value\"] = pairs[\"value\"].to_list()\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cb6ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to huggingface dataset to make use of their batch processing\n",
    "# (I really just wanted the progress bar...)\n",
    "data = Dataset.from_pandas(dataframe)\n",
    "dataframe = data.map(split, batch_size=32, batched=True).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6137678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe for later use\n",
    "dataframe.to_pickle(\"../data/moral_stories_proto_l2s.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcc2e91",
   "metadata": {},
   "source": [
    "## Extracting the actor names\n",
    "***\n",
    "Our simple assumption: The name that comes up most in the row is likely to be the central person in the situation, a.k.a the actor. Therefore, we stitch together all parts of each moral story, apply POS tagging and find the most frequent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6e59a4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 143988/143988 [00:00<00:00, 754023.00it/s]\n"
     ]
    }
   ],
   "source": [
    "dataframe = pd.read_pickle(\"../data/moral_stories_proto_l2s.dat\")\n",
    "# remove \"\"\n",
    "def unquote(s):\n",
    "    if not isinstance(s, str): return s\n",
    "    if len(s) == 0: return s\n",
    "    if s[0] in \"\\\"'\" and s[-1] in \"\\\"'\":\n",
    "        s = s[1:-1]\n",
    "    return s\n",
    "dataframe = dataframe.progress_applymap(unquote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "30cfad99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Token, Span\n",
    "from spacy.language import Language\n",
    "from gender_guesser.detector import Detector\n",
    "\n",
    "# add a token extension that looks itself up in a name dict\n",
    "\n",
    "name_det = Detector(case_sensitive=True)\n",
    "name_det.names.update({\"Benard\":{\"male\":\"1\"},\n",
    "                       \"Haru\":{\"male\":\"1\"}, \n",
    "                       \"Carlow\":{\"male\":\"1\"},\n",
    "                       \"Bently\":{\"male\":\"1\"},\n",
    "                       \"Doro\":{\"male\":\"1\"}\n",
    "                      })\n",
    "\n",
    "def is_name(token):\n",
    "    return token.text in name_det.names\n",
    "\n",
    "Token.set_extension(\"is_name\", getter=is_name, force=True)\n",
    "\n",
    "# add a custom component that filters out the names from our entity ruler matches\n",
    "@Language.component(\"name_filter\")\n",
    "def name_filter(doc):\n",
    "    new_ents = []\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"NAME\" and len(ent) > 1:\n",
    "            new_ent = Span(doc, ent.start, ent.start+1, label=ent.label)\n",
    "            new_ents.append(new_ent)\n",
    "        else:\n",
    "            new_ents.append(ent)\n",
    "    # if there are more than one entity, try to get rid of non-names\n",
    "    if len(new_ents)>1:\n",
    "        new_ents = [x for x in new_ents if x[0]._.is_name]\n",
    "    # take the first one, if there are still more\n",
    "    if len(new_ents)>1:\n",
    "        new_ents = new_ents[:1]\n",
    "    doc.ents = new_ents\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "782459d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos tag the moral stories with custom patterns to find names\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"textcat\"])\n",
    "\n",
    "ruler = nlp.add_pipe(\"entity_ruler\", validate=True)\n",
    "nlp.add_pipe(\"name_filter\", after=\"entity_ruler\")\n",
    "\n",
    "do = {\"OP\":\"?\", \"LEMMA\":\"do\"}\n",
    "nt = {\"OP\":\"?\", \"LEMMA\":\"n't\"}\n",
    "adv = {\"OP\":\"?\", \"POS\":\"ADV\"}\n",
    "action_verbs = [do, nt, adv, {\"LEMMA\":{\"IN\":[\"wants\",\"want\",\"need\",\"have\"]}}]\n",
    "\n",
    "patterns = [\n",
    "    {\"label\":\"NAME\", \"pattern\":[{\"POS\": {\"IN\":[\"PROPN\",\"NOUN\"]}}] + action_verbs},\n",
    "    {\"label\":\"NAME\", \"pattern\":[{\"_\":{\"is_name\": True}}] + action_verbs},\n",
    "]\n",
    "ruler.add_patterns(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "dff27616",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 11999/11999 [00:43<00:00, 275.44it/s]\n"
     ]
    }
   ],
   "source": [
    "docs = dataframe[\"intention\"].progress_apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "6b0ea4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all docs with ties\n",
    "counts = docs.apply(lambda doc: Counter([x[0].text for x in doc.ents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "cfedd31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all docs with ties, should be empty\n",
    "counts = docs.apply(lambda doc: Counter([x[0].text for x in doc.ents]))\n",
    "\n",
    "def f(c):\n",
    "    if len(c) in {0,1}: return False\n",
    "    a,b = c.most_common(2)\n",
    "    if a[1] == b[1]: return True\n",
    "    return False\n",
    "\n",
    "d = dataframe[counts.apply(f)]\n",
    "assert 0 == len(d[[\"intention\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3507ba7",
   "metadata": {},
   "source": [
    "#### Special rules\n",
    "***\n",
    "We apply some special rules for the rest of the bunch\\\n",
    "**Note:** The NLP pipeline should not be used again after this, since the additional rules are extremely sensitive and only suited for the remaining special cases!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "0bad1755",
   "metadata": {},
   "outputs": [],
   "source": [
    "weak_patterns = [\n",
    "    {\"label\":\"NAME\", \"pattern\":[\n",
    "        {\"IS_SENT_START\":True,\"POS\": {\"IN\":[\"PROPN\",\"NOUN\"]}}\n",
    "    ]}\n",
    "]\n",
    "ruler.add_patterns(weak_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "82def222",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255                             (The, alcohol, made, Connie, horny, ,, and, she, wanted, to, have, sex, .)\n",
       "1296                        (She, wants, to, ask, her, friend, April, to, give, her, a, ride, to, work, .)\n",
       "1979                                                                (She, wants, to, spend, the, money, .)\n",
       "2356                                                            (She, wants, to, hire, a, new, manager, .)\n",
       "2360                                          (She, wants, to, prepare, for, trick, -, or, -, treaters, .)\n",
       "2446                                      (He, sees, a, toy, he, likes, and, wants, to, take, it, home, .)\n",
       "2706                                                   (She, wants, to, give, them, something, to, eat, .)\n",
       "4021                                          (She, wants, to, decide, what, to, do, with, the, wallet, .)\n",
       "4291                                                     (She, wants, to, let, him, do, something, fun, .)\n",
       "4562                                   (Wants, to, appear, as, if, the, break, up, did, n't, hurt, her, .)\n",
       "4892                            (She, has, to, drive, her, friend, Carol, to, the, airport, next, week, .)\n",
       "5392                                                                   (She, wants, to, begin, roofing, .)\n",
       "6516                                                           (She, wants, to, send, out, invitations, .)\n",
       "6657                               (Mooz, wants, to, decide, if, he, should, call, his, friend, 's, ex, .)\n",
       "6711                   (Thiago, wants, to, find, out, why, the, classmate, does, n't, have, any, lunch, .)\n",
       "6772                                                                   (She, needs, to, pay, her, rent, .)\n",
       "7354                                                     (Wanted, to, go, take, the, dog, for, a, walk, .)\n",
       "7703                                             (She, wants, to, decide, how, to, design, her, resume, .)\n",
       "8691                                                                   (She, wants, something, to, eat, .)\n",
       "9130                                                    (Wants, to, have, the, best, wedding, possible, .)\n",
       "9294     (She, wants, to, celebrate, this, milestone, with, her, best, friend, by, flying, to, Ireland, .)\n",
       "10084                     (She, wants, to, respond, to, the, person, who, is, expressing, this, belief, .)\n",
       "10422                                         (She, wants, to, clean, up, a, little, before, she, goes, .)\n",
       "10505                                                               (DAwn, wants, a, peaceful, wedding, .)\n",
       "10531                              (Jared, to, wants, to, talk, to, his, grandmother, about, the, vase, .)\n",
       "10581                                              (She, wants, to, be, in, a, relationship, with, him, .)\n",
       "11218                                                                  (She, wants, to, quit, her, job, .)\n",
       "Name: intention, dtype: object"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find all docs without any names\n",
    "remaining = dataframe[\"intention\"][docs.apply(lambda x: len(x.ents)==0)]\n",
    "docs_remaining = remaining.apply(nlp)\n",
    "\n",
    "d  = docs_remaining[docs_remaining.apply(lambda x: len(x.ents)==0)]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "a4334da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mark', 'Mark', 'PROPN'),\n",
       " ('is', 'be', 'AUX'),\n",
       " ('nervous', 'nervous', 'ADJ'),\n",
       " ('about', 'about', 'ADP'),\n",
       " ('being', 'be', 'VERB'),\n",
       " ('away', 'away', 'ADV'),\n",
       " ('and', 'and', 'CCONJ'),\n",
       " ('wants', 'want', 'VERB'),\n",
       " ('to', 'to', 'PART'),\n",
       " ('calm', 'calm', 'VERB'),\n",
       " ('his', 'his', 'PRON'),\n",
       " ('mind', 'mind', 'NOUN'),\n",
       " ('.', '.', 'PUNCT')]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = docs_remaining[645]\n",
    "[(x.text,x.lemma_, x.pos_) for x in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "74a16b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NAME',\n",
       "  'pattern': [{'POS': {'IN': ['PROPN', 'NOUN']}},\n",
       "   {'OP': '?', 'LEMMA': 'do'},\n",
       "   {'OP': '?', 'LEMMA': \"n't\"},\n",
       "   {'OP': '?', 'POS': 'ADV'},\n",
       "   {'LEMMA': {'IN': ['wants', 'want', 'need', 'have']}}]},\n",
       " {'label': 'NAME',\n",
       "  'pattern': [{'_': {'is_name': True}},\n",
       "   {'OP': '?', 'LEMMA': 'do'},\n",
       "   {'OP': '?', 'LEMMA': \"n't\"},\n",
       "   {'OP': '?', 'POS': 'ADV'},\n",
       "   {'LEMMA': {'IN': ['wants', 'want', 'need', 'have']}}]}]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ruler.patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884f5580",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
