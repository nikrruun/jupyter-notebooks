{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "psychological-occupation",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 3: NLP\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-charles",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Agenda\n",
    "***\n",
    "* Recap RL challenge\n",
    "* Lecture on NLP\n",
    "    * Word2vec\n",
    "    * Transformer networks\n",
    "* Challenge 4: Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-skill",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reinforcement learning challenge\n",
    "***\n",
    "Two environments:\n",
    "* Easy: `LunarLander-v2`\n",
    "    * Default gym from OpenAI\n",
    "* Hard: `LunarLander-hardcore-v2`\n",
    "    * Adapted version with different starting positions, more terrain and randomization\n",
    "<center>\n",
    "<video width=\"50%\" controls src=\"img/slides/ll_ep50.mp4\" type=\"video/mp4\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sporting-healthcare",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Solution\n",
    "***\n",
    "Best posted solution:\n",
    "* Single `Dense` layer with `relu` activation, 256 units\n",
    "* `Nadam` optimizer, `lr=0.005` on `MSE` loss\n",
    "* `discount=0.99`\n",
    "* Trained for 10k episodes\n",
    "\n",
    "The tricks:\n",
    "* Run `n` episodes, but only train on the `top_n` runs with highest reward\n",
    "    * Idea: Give higher influence to positive reinforcement\n",
    "        * Here: Train on top 2 rewarding episodes of 10 trials\n",
    "* Finetune agents from the easy gym for the hard environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-netherlands",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Results\n",
    "***\n",
    "Two agents:\n",
    "* (E) Trained solely in the easy env\n",
    "* (H) The same model, but finetuned in the hard environment\n",
    "\n",
    "Easy:\n",
    "* (E): `Agent achieved 279.70 mean reward over 1000 runs`\n",
    "* (H): `Agent achieved 258.77 mean reward over 1000 runs`\n",
    "\n",
    "Hard:\n",
    "* (E): `Agent achieved 224.53 mean reward over 1000 runs`\n",
    "* (H): `Agent achieved 270.21 mean reward over 1000 runs`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-privacy",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Comparison on `easy`\n",
    "***\n",
    "<center><div style=\"display:flex; justify-content: space-evenly;\">\n",
    "    <div style=\"flex-basis:40%\">\n",
    "        <center>Agent E</center>\n",
    "        <video width=\"95%\" controls src=\"img/slides/ll_easy_solved.mp4\" type=\"video/mp4\" />\n",
    "    </div>\n",
    "    <div style=\"flex-basis:40%\">\n",
    "        <center>Agent H</center>\n",
    "        <video width=\"95%\" controls src=\"img/slides/ll_hard_transfer.mp4\" type=\"video/mp4\" />\n",
    "    </div>\n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-template",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Comparison on `hard`\n",
    "***\n",
    "<center><div style=\"display:flex; justify-content: space-evenly;\">\n",
    "    <div style=\"flex-basis:40%\">\n",
    "        <center>Agent E</center>\n",
    "        <video width=\"95%\" controls src=\"img/slides/ll_easy_transfer.mp4\" type=\"video/mp4\" />\n",
    "    </div>\n",
    "    <div style=\"flex-basis:40%\">\n",
    "        <center>Agent H</center>\n",
    "        <video width=\"95%\" controls src=\"img/slides/ll_hard_solved.mp4\" type=\"video/mp4\" />\n",
    "    </div>\n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-mountain",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Natural language processing\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-poultry",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What is NLP?\n",
    "***\n",
    "Everything we express carries huge amounts of information\n",
    "* what words we use and in which context\n",
    "* our tone of voice\n",
    "* ...\n",
    "\n",
    "People are (more or less :D) able to understand other people\n",
    "* BUT computers definitly not yet \n",
    "\n",
    "**Natural Language Processing** is about:\n",
    "* field of research to make machines unterstand and derive meaning from human languages\n",
    "* often ML based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-terminal",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Use Cases of NLP: Chatbot\n",
    "***\n",
    "<img src=\"img/slides/chatbot_fails.png\" style=\"float: middle;\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-feedback",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Use Cases of NLP: Disease Diagnosis\n",
    "***\n",
    "<img src=\"img/slides/diagnose_patients.png\" style=\"float: left;\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-flash",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Use Cases of NLP: Knowledge Extraction\n",
    "***\n",
    "<img src=\"img/slides/knowledge_extraction.png\" style=\"float: left;\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-intellectual",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Use Cases of NLP: Translation\n",
    "***\n",
    "<img src=\"img/slides/translation.png\" style=\"float: left;\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-scoop",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Use Cases of NLP: Sentiment Analysis\n",
    "***\n",
    "<img src=\"img/slides/sentiments_analysis.png\" width= 700 style=\"float: middle;\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-settle",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# But how to represent the meaning of a word\n",
    "***\n",
    "Commonest linguistic way of thinking of meaning:\n",
    "* signifier (symbol) ⟺ signified (idea or thing)\n",
    "\n",
    "How about synonyms? Use WordNet!\n",
    "* Example: good\n",
    "    * goodness\n",
    "    * honorable\n",
    "    * beneficial\n",
    "    * upright\n",
    "    * well\n",
    "    * proficient\n",
    "    * exellent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-patio",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Problems with resources like WordNet\n",
    "***\n",
    "Great as a resource but missing nuance\n",
    "* e.g., “proficient” is listed as a synonym for “good” (This is only correct in some contexts)\n",
    "\n",
    "Missing new meanings of words\n",
    "\n",
    "Requires human labor to create and adapt\n",
    "\n",
    "Can’t compute accurate word similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-affiliate",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Representing words as discrete symbols\n",
    "***\n",
    "determine a vocabulary $V = \\{expect, movie, is, good, but,  exellent\\}$\n",
    "* create one-hot encoded vectors\n",
    "\n",
    "$expect = \\begin{pmatrix} 1\\\\0\\\\0\\\\0\\\\0\\\\0 \\end{pmatrix},\\; movie = \\begin{pmatrix} 0\\\\1\\\\0\\\\0\\\\0\\\\0 \\end{pmatrix},\\; is = \\begin{pmatrix} 0\\\\0\\\\1\\\\0\\\\0\\\\0 \\end{pmatrix},\\; good = \\begin{pmatrix} 0\\\\0\\\\0\\\\1\\\\0\\\\0 \\end{pmatrix},\\; but = \\begin{pmatrix} 0\\\\0\\\\0\\\\0\\\\1\\\\0 \\end{pmatrix},\\; exellent = \\begin{pmatrix} 0\\\\0\\\\0\\\\0\\\\0\\\\1 \\end{pmatrix} $\n",
    "\n",
    "visualize these encodings, we can think of a 6 dimensional space\n",
    "* each word occupies one of the dimensions and has nothing to do with the rest \n",
    "* This means ‘good’ and ‘exellent’ are as different as ‘expect’ and ‘is’, which is not true\n",
    "* Solution: learn to encode similarity in the vectors themselves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-crest",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Representing words by their context\n",
    "***\n",
    "When a word $w \\in V$ appears in a text, its context is the set by words that appear nearby (within a fixed-size window)\n",
    "* Use the many contexts of $w$ to build up a representation of $w$\n",
    "* for each $w$ a word vector is built, chosen so that it is similar to vectors of words that appear in similar contexts\n",
    "\n",
    "**Note**: word vectors are also called word embeddings or (neural) word representations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guilty-audience",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Word meaning as a word embedding\n",
    "***\n",
    "$is = \\begin{pmatrix} 0.784\\\\ 0.629\\\\−0.205\\\\−0.176\\\\0.211\\\\−0.563\\\\0.418\\\\0.189\\\\-0.621 \\end{pmatrix}$ <img src=\"img/slides/word_embedding.png\" width=\"700\" style=\"border: 1px black; float: right;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convenient-stack",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Constructing word embeddings: Word2Vec\n",
    "***\n",
    "Two possible methods\n",
    "* Skip Gram\n",
    "* Common Bag Of Words (CBOW)\n",
    "\n",
    "Let's focus on Skip Grams! (It is better for large datasets)\n",
    "* Skip Gram model considers center word as input and predicts context words\n",
    "\n",
    "<img src=\"img/slides/skip_gram.png\" style=\"height: 300px; float: left;\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "middle-rings",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Architecture of Word2Vec\n",
    "***\n",
    "2-layer neural network\n",
    "* input layer requires one-hot vectors\n",
    "* hidden layer is dense layer whose weights will be the word embeddings\n",
    "* output layer + softmax outputs probabilities for words from the vocabulary\n",
    "\n",
    "<img src=\"img/slides/Word2vec.png\" width= 700 style=\"float: middle;\">\n",
    "\n",
    "**Note**: figure reproduced from https://israelg99.github.io/2017-03-23-Word2Vec-Explained/ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-accent",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Training of Word2Vec\n",
    "***\n",
    "\n",
    "Training\n",
    "* Train the weights of the hidden layer and output layer with the help of skip gram model\n",
    "* cut off the output layer to get the embeddings\n",
    "\n",
    "<img src=\"img/slides/Word2vec.png\" width= 700 style=\"float: middle;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-hammer",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Training of Word2Vec: Example\n",
    "***\n",
    "<img src=\"img/slides/skip_gram.png\" style=\"height:300px; float: right;\">\n",
    "\n",
    "determine the vocabulary $V = \\{expect, the, movie, is, good, but\\}$\n",
    "\n",
    "train the hidden weights (= word embedding) for the word \"is\" for the given input and output with gradient descent algo\n",
    "\n",
    "$input: \\begin{pmatrix} 0\\\\0\\\\0\\\\1\\\\0\\\\0 \\end{pmatrix} \\; output: \\begin{pmatrix} 0\\\\1\\\\1\\\\0\\\\1\\\\1 \\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-salem",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Training of Word2Vec\n",
    "***\n",
    "<img src=\"img/slides/Word2vec.png\" width= 600 style=\"float: middle;\">\n",
    "\n",
    "If different words are similar in context, then Word2Vec should have similar outputs when these words are passed as inputs\n",
    "* in-order to have a similar outputs, the computed word embeddings  for these words have to be similar\n",
    "* thus Word2Vec is motivated to learn similar word embeddings for words in similar context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-petersburg",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What can you do with word embeddings?\n",
    "***\n",
    "<img src=\"img/slides/embedding_example.png\" style=\"\">\n",
    "\n",
    "**Note**: figure reproduced from https://israelg99.github.io/2017-03-23-Word2Vec-Explained/ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-cincinnati",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Language Modeling\n",
    "***\n",
    "based on Markov Assumption: assumption that the $t+1$st word is dependent on the previous $t$ words\n",
    "\n",
    "Language Modeling is the task of predicting what word comes next\n",
    "* \"The students opened their ____\" $\\rightarrow$ \\[books, laptops, exams, minds\\]\n",
    "\n",
    "Formally:\\\n",
    "Given a sequence of words $x^{(1)}, x^{(2)}, ..., x^{(t)}$, compute the probability distribution of the next word $x^{(t+1)}$:\n",
    "\n",
    "$P(x^{(t+1)} \\vert x^{(t)}, ..., x^{(1)})$\n",
    "\n",
    "where $x^{(t+1)}$ can be any word in the vocabulary $V = \\{w_1, ..., w_{\\vert V \\vert}\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-belfast",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# You use Language Models every day!\n",
    "***\n",
    "<img src=\"img/slides/lm_google.png\" style=\"float: middle;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-upgrade",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# n-gram Language Models\n",
    "***\n",
    "\"The students opened their ____\"\n",
    "\n",
    "**Definition**: A n-gram is a chunk of n consecutive words\n",
    "* unigrams: “the”, “students”, “opened”, ”their”\n",
    "* bigrams: “the students”, “students opened”, “opened their”\n",
    "* trigrams: “the students opened”, “students opened their”\n",
    "* 4-grams: “the students opened their”\n",
    "\n",
    "**Idea**: Collect statistics about how frequent different n-grams are and use these to predict next word (no deep learning!)\n",
    "\n",
    "**Hint**: IfIS lecture on Information Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hired-rehabilitation",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# n-gram Language Models\n",
    "***\n",
    "Suppose we are learning a 4-gram Language Model:\n",
    "<img src=\"img/slides/n_gram_lm.png\" style=\"\">\n",
    "\n",
    "\n",
    "$P(w|\\text{students opened their})=\\frac{\\text{count(students opened their w})}{\\text{count(students opened their)}}$\n",
    "\n",
    "For example, suppose that in the corpus:\n",
    "* \"students opened their\" occurred 1000 times\n",
    "* \"students opened their **books**\" occurred 400 times\n",
    "    * $P(\\text{books} | \\text{students opened their}) = 0.4$\n",
    "* \"students opened their **exams**\" occurred 100 times\n",
    "    * $P(\\text{exams} | \\text{students opened their}) = 0.1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-defendant",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Problems with n-gram Language Models\n",
    "***\n",
    "What if \"students opened their\" never occurred in data? Then we can’t calculate probability for any $w$\n",
    "\n",
    "Need to store count for all n-grams you saw in the corpus\n",
    "* could need to consider more than n words at a time if we want to model language well\n",
    "* but considering big $n$ need much storage\n",
    "\n",
    "**Solution**: As always, neural networks! (Because neural networks are great \\*grins\\*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-wesley",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Neural Language Models\n",
    "***\n",
    "<img src=\"img/slides/neural_LM.png\" width=550 style=\"float: right;\">\n",
    "\n",
    "Input sentence: $w_1, ..., w_5 \\rightarrow $ strings\n",
    "\n",
    "Neural network cannot understand strings and would rather have numbers\\\n",
    "as input\n",
    "* \\*jay\\* we can use our word embeddings\n",
    "* so feed input sentence to neural network with the help \\\n",
    "of the  word embeddings\n",
    "\n",
    "At the end classfication layer for e.g. sentiment analysis\n",
    "\n",
    "Magic based on **CNNs** or **RNNs** or **Transformers** or ... But wait, what are all these things?\n",
    "\n",
    "Let's start with something we already know: CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emerging-balloon",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Neural Language Models based on CNNs\n",
    "***\n",
    "**idea**: tackle dependencies by applying different kernels to the same sentence\n",
    "* a kernel of size 2 for example learns relationships between pairs of words, a kernel of size 3 between triplets of words and so on\n",
    "\n",
    "**problem**: too costly to capture possible combinations of words in a sentence $\\rightarrow$ many and big kernels needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-debut",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Neural Language Models based on RNNs\n",
    "***\n",
    "<img src=\"img/slides/RNN.png\" width= 550 style=\"float: right;\">\n",
    "\n",
    "**idea**: not just consider the actual sentences but also previous sentences to memorize what happens previously\n",
    "\n",
    "**problem**: Sequential processing\n",
    "* to encode the second word in a sentence it needs the previously\\\n",
    "computed hidden states of the first word\n",
    "\n",
    "**problem**: Short memorization\n",
    "* encoding of a specific word is retained only for the next time step $\\rightarrow$ encoding of word strongly affect only the representation of the next word\n",
    "* influence is quickly lost after few time steps (LSTMs (Long short-term memory) can boost a bit the memorization)\n",
    "\n",
    "**Note**: figure reproduced from \\\n",
    "https://medium.com/swlh/simple-explanation-of-recurrent-neural-network-rnn-1285749cc363"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-store",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Language Models based on Transformers\n",
    "***\n",
    "<img src=\"img/slides/transformer.png\" style=\"width: 700px; float: right;\">\n",
    "\n",
    "Transformers solves all issius of CNNs and RNNs with\n",
    "encoder-decoder architectur and self-attention \n",
    "\n",
    "**encoder**:\n",
    "* input (positional word embeddings) first flows through a self-attention layer\n",
    "    * self-attention helps the encoder look at other words in the input sentence\n",
    "* the outputs of the self-attention layer are fed to a feed-forward neural network\n",
    "\n",
    "**decoder**:\n",
    "* also self-attention layer and feed-forward neural network\n",
    "* in between is an attention layer that helps the decoder focus on relevant parts of the input sentence\n",
    "\n",
    "\n",
    "\n",
    "**Note**: figure reproduced from https://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-detail",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Transformer: Self-Attention\n",
    "***\n",
    "<img src=\"img/slides/exbert_input.png\" style=\"\">\n",
    "<img src=\"img/slides/exbert_output.png\" style=\"\">\n",
    "\n",
    "Example: What does “it” in this sentence refer to?\n",
    "* self attention allows it to look at other positions in the input sequence to get a better encoding for this word\n",
    "\n",
    "**Note**: creating attention plots: https://exbert.net/exBERT.html?model=bert-base-cased&modelKind=bidirectional&sentence=This%20movie%20is%20terrible%20but%20it%20has%20some%20good%20effects.&corpus=woz&layer=1&heads=..9&threshold=0.5&tokenInd=6&tokenSide=right&maskInds=..&metaMatch=pos&metaMax=pos&displayInspector=null&offsetIdxs=..-1,0,1&hideClsSep=true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tough-crystal",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How can we calculate attention scores?\n",
    "***\n",
    "create three vectors from each of the encoder’s input word embeddings: Query vector, Key vector, Value vector\n",
    "* these vectors are created by multiplying the embedding by three matrices that we trained during the training process\n",
    "\n",
    "with these three vectors and after a few more steps... we can calculate an attention score\n",
    "\n",
    "**Note**: detailed explaination at https://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-feedback",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pre-Training and Fine-Tuning\n",
    "***\n",
    "<img src=\"img/slides/pre_training_embeddings.png\" style=\"\">\n",
    "\n",
    "**Idea**:\n",
    "* Only pre-train the embeddings (e.g. Word2Vec)\n",
    "* Put on top a neural network/classification layer\n",
    "    * incorporate context while training on a downstream task (e.g. sentiment anlysis)\n",
    "\n",
    "**Problem**: training data for downstream task must be sufficient to teach all contextual aspects of language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-valuation",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pre-Training and Fine-Tuninig\n",
    "***\n",
    "<img src=\"img/slides/pre_training_all.png\" style=\"float: middle;\">\n",
    "\n",
    "**Idea**:\n",
    "* all weights are initialized via pre-training\n",
    "* fine-tune only with small training data on downstream task (e.g. sentiment analysis) because during pre-training the general contextual knowledge was already teached"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-polymer",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Language Models: GPT\n",
    "***\n",
    "<img src=\"img/slides/decoders.png\" width= 200 style=\"float: right;\">\n",
    "\n",
    "GPT (Generative Pretrained Transformer)\n",
    "* based on pre-trained decoders\n",
    "* helpful in tasks where the output is a sequence with a vocabulary like that in pre-training\n",
    "    * e.g. Translation, Summarization, ...\n",
    "\n",
    "**Note**: GPT-2 or GPT-3 are mostly the same architecture but are trained on more/other tasks and muuuch more data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-dryer",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Language Models: BERT\n",
    "***\n",
    "<img src=\"img/slides/encoder.png\" width= 500 style=\"float: right;\">\n",
    "\n",
    "BERT (Bidirectional Encoder Representations from Transformers)\n",
    "* based on pre-trained encoders\n",
    "* encoder get bidirectional context by using \\[MASK\\]-token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-cooperative",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let's go for a little deep dive into BERT!\n",
    "***\n",
    "<div style=\"float: right; display: grid; grid-auto-rows: 50% 50%;\">\n",
    "<img src=\"img/slides/bert-base-bert-large.png\" width= 500 style=\"float: left;\">\n",
    "<img src=\"img/slides/bert-base-bert-large-encoders.png\" width= 500 style=\"float: left;\">\n",
    "</div>\n",
    "\n",
    "two main models\n",
    "* BERT base\n",
    "* BERT large\n",
    "\n",
    "differ in:\n",
    "* number of encoder layers (12 vs 24)\n",
    "* number of parameter in feed-forward networks (768 vs 1024)\n",
    "* multi-head attention (12 vs 16)\n",
    "\n",
    "**Note**: figure reproduced from http://jalammar.github.io/illustrated-bert/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peripheral-energy",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# BERT: Pre-Training and Fine-Tuning\n",
    "***\n",
    "Pre-training on Books Corpus und English Wikipedia\n",
    "* using two tasks to teach contextual knowledge\n",
    "    * fill-mask task, next sentence prediction task\n",
    "* semi-supervised\n",
    "* **Note**: you can use BERT already after pre-training for the two tasks (fill-mask and next sentence prediction)\n",
    "    \n",
    "Fine-tuning on your favourite downstream task\n",
    "* \"Pre-train once, fine-tune many times\"\n",
    "* take pre-trained BERT, delete old classification layer and put a new classification layer for your downstream task on top\n",
    "* downstream tasks like spam classifier, sentiment analysis, fact checker, special fill-mask task (e.g. to predict facts), ...\n",
    "* supervised"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-tours",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# BERT: fixed vocabulary\n",
    "***\n",
    "<img src=\"img/slides/BERT_basecased_vocab.png\" width= 250 style=\"float: right;\">\n",
    "\n",
    "Vocabulary of BERT base consists of tokens which BERT can \"understand\" and can predict for \\[MASK\\]-token\n",
    "\n",
    "If a word of the input sentence is not in the vocabulary, BERT can put it together with tokens\n",
    "* has nothing to do with real syllables\n",
    "* extension to words that are not in the vocabulary but can be composed of tokens\n",
    "* e.g. incredible $\\rightarrow$ incred ##ible (Only for explanatory purposes, normally\\\n",
    "\"incredible\" is in the vocabulary)\n",
    "\n",
    "BUT BERT can only predict **single-token** of its vocabulary for \\[MASK\\]-token\n",
    "* e.g. Edinburgh $\\rightarrow$ Edinburgh (can predict \"Edinburgh\" because it is a single token)\n",
    "* e.g. incredible $\\rightarrow$ incred ##ible (cannot predict \"incredible\" because two tokens, could only predict \"incred\" **or** \"##ible\")\n",
    "\n",
    "**Note**: whole-word-masking is a good keyword here if you want to do multi-token prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historical-palestinian",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Talk to pre-trained BERT: fill-mask task\n",
    "***\n",
    "<img src=\"img/slides/BERT_0.png\" width= 700 style=\"float: middle;\">\n",
    "\n",
    "\\[CLS\\]: classification token\n",
    "\n",
    "\\[SEP\\]: seperation token (only needed at e.g next sentence prediction task, but it is always added)\n",
    "\n",
    "\\[PAD\\]: padding token\n",
    "\n",
    "**Note**: figures reproduced from http://jalammar.github.io/illustrated-bert/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-parts",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Look inside of pre-trained BERT\n",
    "***\n",
    "<img src=\"img/slides/BERT_1.png\" width= 700 style=\"float: middle;\">\n",
    "\n",
    "<img src=\"img/slides/pre_training_all.png\" width= 300 style=\"float: right;\">\n",
    "\n",
    "remember figure of pre-training\n",
    "* all weights were initialized during pre-training\n",
    "* BERT learned his own positional embeddings\n",
    "\n",
    "**Note**: figures reproduced from http://jalammar.github.io/illustrated-bert/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-birmingham",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Get prediction of BERT: fill-mask task\n",
    "***\n",
    "<img src=\"img/slides/BERT_2.png\" width= 700 style=\"float: middle;\">\n",
    "\n",
    "**Note**: figures reproduced from http://jalammar.github.io/illustrated-bert/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-three",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Get prediction of BERT: fill-mask task\n",
    "***\n",
    "<img src=\"img/slides/BERT_3.png\" width= 700 style=\"float: middle;\">\n",
    "\n",
    "**Note**: figures reproduced from http://jalammar.github.io/illustrated-bert/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-intervention",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# BERT: Pre-Training with fill-mask task\n",
    "***\n",
    "<img src=\"img/slides/BERT-language-modeling-masked-lm.png\" width= 700 style=\"float: right;\">\n",
    "\n",
    "1) add classification layer  + Softmax (over all tokens of vocabulary) on top of BERT to pre-train BERT on the fill-mask task\n",
    "\n",
    "2) randomly mask 15\\% of the input sentence to teach BERT to predict the correct words for the \\[MASK\\]-tokens\n",
    "* no need to get labels (= semi-supervised) because we \\\n",
    "only omit words of the whole sentence which BERT \\\n",
    "should predict\n",
    "\n",
    "**Note**: figure reproduced from\\\n",
    "http://jalammar.github.io/illustrated-bert/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-arizona",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# BERT: Next sentence prediction task\n",
    "***\n",
    "<img src=\"img/slides/bert-next-sentence-prediction.png\" width= 700 style=\"float: right;\">\n",
    "\n",
    "1) add classification layer + Softmax (two labels: IsNext and NotNext) on top of BERT to pre-train BERT on the next sentence prediction task\n",
    "\n",
    "2) two sentences as input and label (IsNext or NotNext) as output to teach BERT relationships between multiple sentences\n",
    "* no need to get labels (= semi-supervised) because we \\\n",
    "use sentences from BookCorpus and Wikipedia where we \\\n",
    "know whether they are follow each other\n",
    "\n",
    "**Note**: figure reproduced from \\\n",
    "http://jalammar.github.io/illustrated-bert/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "african-emergency",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# BERT: Fine-Tuning\n",
    "***\n",
    "Example downstream task: spam classification\n",
    "\n",
    "Dataset\n",
    "<img src=\"img/slides/spam-labeled-dataset.png\" width= 300 style=\"\">\n",
    "\n",
    "<img src=\"img/slides/bert-classifier.png\" width= 700 style=\"float: right;\">\n",
    "\n",
    "\n",
    "\n",
    "1) cut of the classification layer of the fill-mask and next sentence prediction task\n",
    "\n",
    "2) add classification layer + Softmax (two labels: Spam and NotSpam) on top of BERT to fine-tune BERT on the spam classification task\n",
    "\n",
    "3) email message as input and label (Spam or NotSpam) as output to teach BERT to classify spam\n",
    "\n",
    "**Note**: figures reproduced from http://jalammar.github.io/illustrated-bert/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recent-wayne",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Use fine-tuned BERT to classify spam\n",
    "***\n",
    "use the fine-tuned BERT consisting of the pre-trained part and the new classification layer\n",
    "* BERT can now predict whether a email message, which was not seen during fine-tuning, is spam or not\n",
    "\n",
    "Example spam message: \"Help Prince Mayuko Transfer Huge Inheritance\"\n",
    "<img src=\"img/slides/BERT-classification-spam.png\" width= 700 style=\"float: middle;\">\n",
    "\n",
    "**Note**: figure reproduced from http://jalammar.github.io/illustrated-bert/\n",
    "\n",
    "\n",
    "**BUT WAIT**: Didn't we set out to use BERT for sentiment analysis of movie reviews?!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-nomination",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# It's your turn!\n",
    "***\n",
    "Challenge\n",
    "* fine-tune BERT so that he can predict the sentiment of a movie review\n",
    "* use the IMDb dataset and huggingface framework\n",
    "\n",
    "Objective\n",
    "* get the highest precision by playing around with:\n",
    "    * the models (meanwhile there are much more than BERT base and BERT large)\n",
    "    * the hyperparmeters during fine-tuning\n",
    "    * training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "through-adelaide",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sources\n",
    "***\n",
    "This lecture is based on http://web.stanford.edu/class/cs224n/. It is a really good course! :)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "rise": {
   "auto_select": "none",
   "enable_chalkboard": true,
   "overlay": "<div class='myheader'><img src='img/ai_camp.png' class='ifis_small'></div><div class='ifis_large'><img src='img/ifis_large.png'></div>",
   "scroll": true,
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
